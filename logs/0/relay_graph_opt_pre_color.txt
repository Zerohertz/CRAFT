v0.0.1
%330 = fn (%v0:0: Tensor[(1, 3, 2400, 2400), float32]) -> (Tensor[(1, 1200, 1200, 2), float32], Tensor[(1, 32, 1200, 1200), float32]) {
  %0 = copy(%v0:0, framework_op_name="copy0", output_tensors_name=["copy0:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_5/Conv2d_12/aten__convolution/transpose", axis=0) // ty=Tensor[(1, 3, 2400, 2400), float32]
  %1 = transpose(%0, framework_op_name="vgg16_bn_6/Sequential_5/Conv2d_12/aten__convolution/transpose", output_tensors_name=["vgg16_bn_6/Sequential_5/Conv2d_12/aten__convolution/transpose:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_5/Conv2d_12/aten__convolution/transpose", axes=[0, 2, 3, 1]) // ty=Tensor[(1, 2400, 2400, 3), float32]
  %2 = nn.pad(%1, framework_op_name="vgg16_bn_6/Sequential_5/Conv2d_12/aten__convolution/Pad", output_tensors_name=["vgg16_bn_6/Sequential_5/Conv2d_12/aten__convolution/Pad:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_5/Conv2d_12/aten__convolution/Pad", pad_width=[[0, 0], [1, 1], [1, 1], [0, 0]]) // ty=Tensor[(1, 2402, 2402, 3), float32]
  %3 = transpose(%2, framework_op_name="transpose6", output_tensors_name=["transpose6:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_5/Conv2d_12/aten__convolution/Conv2D", axes=[0, 3, 1, 2]) // ty=Tensor[(1, 3, 2402, 2402), float32]
  %4 = nn.pad(%3, framework_op_name="nn.pad0", output_tensors_name=["nn.pad0:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_5/Conv2d_12/aten__convolution/Conv2D", pad_width=[[0, 0], [0, 0], [0, 0], [0, 2]]) // ty=Tensor[(1, 3, 2402, 2404), float32]
  %5 = nn.conv2d(%4, meta[relay.Constant][0] // ty=Tensor[(3, 3, 3, 64), float32], framework_op_name="nn.conv2d0", output_tensors_name=["nn.conv2d0:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_5/Conv2d_12/aten__convolution/Conv2D", channels=64, kernel_size=[3, 3], kernel_layout="HWIO") // ty=Tensor[(1, 64, 2400, 2402), float32]
  %6 = strided_slice(%5, framework_op_name="strided_slice0", output_tensors_name=["strided_slice0:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_5/Conv2d_12/aten__convolution/Conv2D", begin=[0, 0, 0, 0], end=[1, 64, 2400, 2400], strides=[1, 1, 1, 1]) // ty=Tensor[(1, 64, 2400, 2400), float32]
  %7 = transpose(%6, framework_op_name="vgg16_bn_6/Sequential_5/Conv2d_12/aten__convolution/Conv2D:0", output_tensors_name=["vgg16_bn_6/Sequential_5/Conv2d_12/aten__convolution/Conv2D:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_5/Conv2d_12/aten__convolution/Conv2D:0", axes=[0, 2, 3, 1]) // ty=Tensor[(1, 2400, 2400, 64), float32]
  %8 = add(%7, meta[relay.Constant][1] // ty=Tensor[(64,), float32], framework_op_name="vgg16_bn_6/Sequential_5/Conv2d_12/aten__convolution/BiasAdd", output_tensors_name=["vgg16_bn_6/Sequential_5/Conv2d_12/aten__convolution/BiasAdd:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_5/Conv2d_12/aten__convolution/BiasAdd", axis=0) // ty=Tensor[(1, 2400, 2400, 64), float32]
  %9 = transpose(%8, framework_op_name="vgg16_bn_6/Sequential_5/Conv2d_12/aten__convolution/transpose_2", output_tensors_name=["vgg16_bn_6/Sequential_5/Conv2d_12/aten__convolution/transpose_2:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_5/Conv2d_12/aten__convolution/transpose_2", axes=[0, 3, 1, 2]) // ty=Tensor[(1, 64, 2400, 2400), float32]
  %10 = transpose(%9, framework_op_name="vgg16_bn_6/Sequential_5/BatchNorm2d_13/aten_batch_norm/transpose", output_tensors_name=["vgg16_bn_6/Sequential_5/BatchNorm2d_13/aten_batch_norm/transpose:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_5/BatchNorm2d_13/aten_batch_norm/transpose", axes=[0, 2, 3, 1]) // ty=Tensor[(1, 2400, 2400, 64), float32]
  %11 = subtract(%10, meta[relay.Constant][2] // ty=Tensor[(64,), float32], framework_op_name="vgg16_bn_6/Sequential_5/BatchNorm2d_13/aten_batch_norm/sub", output_tensors_name=["vgg16_bn_6/Sequential_5/BatchNorm2d_13/aten_batch_norm/sub:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_5/BatchNorm2d_13/aten_batch_norm/sub", axis=0) // ty=Tensor[(1, 2400, 2400, 64), float32]
  %12 = multiply(%11, meta[relay.Constant][3] // ty=Tensor[(64,), float32], framework_op_name="vgg16_bn_6/Sequential_5/BatchNorm2d_13/aten_batch_norm/truediv", output_tensors_name=["vgg16_bn_6/Sequential_5/BatchNorm2d_13/aten_batch_norm/truediv:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_5/BatchNorm2d_13/aten_batch_norm/truediv", axis=0) // ty=Tensor[(1, 2400, 2400, 64), float32]
  %13 = multiply(%12, meta[relay.Constant][4] // ty=Tensor[(64,), float32], framework_op_name="vgg16_bn_6/Sequential_5/BatchNorm2d_13/aten_batch_norm/mul", output_tensors_name=["vgg16_bn_6/Sequential_5/BatchNorm2d_13/aten_batch_norm/mul:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_5/BatchNorm2d_13/aten_batch_norm/mul", axis=0) // ty=Tensor[(1, 2400, 2400, 64), float32]
  %14 = add(%13, meta[relay.Constant][5] // ty=Tensor[(64,), float32], framework_op_name="vgg16_bn_6/Sequential_5/BatchNorm2d_13/aten_batch_norm/add_1", output_tensors_name=["vgg16_bn_6/Sequential_5/BatchNorm2d_13/aten_batch_norm/add_1:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_5/BatchNorm2d_13/aten_batch_norm/add_1", axis=0) // ty=Tensor[(1, 2400, 2400, 64), float32]
  %15 = transpose(%14, framework_op_name="vgg16_bn_6/Sequential_5/BatchNorm2d_13/aten_batch_norm/transpose_1", output_tensors_name=["vgg16_bn_6/Sequential_5/BatchNorm2d_13/aten_batch_norm/transpose_1:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_5/BatchNorm2d_13/aten_batch_norm/transpose_1", axes=[0, 3, 1, 2]) // ty=Tensor[(1, 64, 2400, 2400), float32]
  %16 = nn.relu(%15, framework_op_name="vgg16_bn_6/Sequential_5/BatchNorm2d_13/aten_relu/Relu", output_tensors_name=["vgg16_bn_6/Sequential_5/BatchNorm2d_13/aten_relu/Relu:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_5/BatchNorm2d_13/aten_relu/Relu", axis=0) // ty=Tensor[(1, 64, 2400, 2400), float32]
  %17 = transpose(%16, framework_op_name="vgg16_bn_6/Sequential_5/Conv2d_15/aten__convolution/transpose", output_tensors_name=["vgg16_bn_6/Sequential_5/Conv2d_15/aten__convolution/transpose:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_5/Conv2d_15/aten__convolution/transpose", axes=[0, 2, 3, 1]) // ty=Tensor[(1, 2400, 2400, 64), float32]
  %18 = nn.pad(%17, framework_op_name="vgg16_bn_6/Sequential_5/Conv2d_15/aten__convolution/Pad", output_tensors_name=["vgg16_bn_6/Sequential_5/Conv2d_15/aten__convolution/Pad:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_5/Conv2d_15/aten__convolution/Pad", pad_width=[[0, 0], [1, 1], [1, 1], [0, 0]]) // ty=Tensor[(1, 2402, 2402, 64), float32]
  %19 = nn.conv2d(%18, meta[relay.Constant][6] // ty=Tensor[(3, 3, 64, 64), float32], framework_op_name="vgg16_bn_6/Sequential_5/Conv2d_15/aten__convolution/Conv2D", output_tensors_name=["vgg16_bn_6/Sequential_5/Conv2d_15/aten__convolution/Conv2D:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_5/Conv2d_15/aten__convolution/Conv2D", channels=64, kernel_size=[3, 3], data_layout="NHWC", kernel_layout="HWIO") // ty=Tensor[(1, 2400, 2400, 64), float32]
  %20 = add(%19, meta[relay.Constant][7] // ty=Tensor[(64,), float32], framework_op_name="vgg16_bn_6/Sequential_5/Conv2d_15/aten__convolution/BiasAdd", output_tensors_name=["vgg16_bn_6/Sequential_5/Conv2d_15/aten__convolution/BiasAdd:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_5/Conv2d_15/aten__convolution/BiasAdd", axis=0) // ty=Tensor[(1, 2400, 2400, 64), float32]
  %21 = transpose(%20, framework_op_name="vgg16_bn_6/Sequential_5/Conv2d_15/aten__convolution/transpose_2", output_tensors_name=["vgg16_bn_6/Sequential_5/Conv2d_15/aten__convolution/transpose_2:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_5/Conv2d_15/aten__convolution/transpose_2", axes=[0, 3, 1, 2]) // ty=Tensor[(1, 64, 2400, 2400), float32]
  %22 = transpose(%21, framework_op_name="vgg16_bn_6/Sequential_5/BatchNorm2d_16/aten_batch_norm/transpose", output_tensors_name=["vgg16_bn_6/Sequential_5/BatchNorm2d_16/aten_batch_norm/transpose:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_5/BatchNorm2d_16/aten_batch_norm/transpose", axes=[0, 2, 3, 1]) // ty=Tensor[(1, 2400, 2400, 64), float32]
  %23 = subtract(%22, meta[relay.Constant][8] // ty=Tensor[(64,), float32], framework_op_name="vgg16_bn_6/Sequential_5/BatchNorm2d_16/aten_batch_norm/sub", output_tensors_name=["vgg16_bn_6/Sequential_5/BatchNorm2d_16/aten_batch_norm/sub:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_5/BatchNorm2d_16/aten_batch_norm/sub", axis=0) // ty=Tensor[(1, 2400, 2400, 64), float32]
  %24 = multiply(%23, meta[relay.Constant][9] // ty=Tensor[(64,), float32], framework_op_name="vgg16_bn_6/Sequential_5/BatchNorm2d_16/aten_batch_norm/truediv", output_tensors_name=["vgg16_bn_6/Sequential_5/BatchNorm2d_16/aten_batch_norm/truediv:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_5/BatchNorm2d_16/aten_batch_norm/truediv", axis=0) // ty=Tensor[(1, 2400, 2400, 64), float32]
  %25 = multiply(%24, meta[relay.Constant][10] // ty=Tensor[(64,), float32], framework_op_name="vgg16_bn_6/Sequential_5/BatchNorm2d_16/aten_batch_norm/mul", output_tensors_name=["vgg16_bn_6/Sequential_5/BatchNorm2d_16/aten_batch_norm/mul:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_5/BatchNorm2d_16/aten_batch_norm/mul", axis=0) // ty=Tensor[(1, 2400, 2400, 64), float32]
  %26 = add(%25, meta[relay.Constant][11] // ty=Tensor[(64,), float32], framework_op_name="vgg16_bn_6/Sequential_5/BatchNorm2d_16/aten_batch_norm/add_1", output_tensors_name=["vgg16_bn_6/Sequential_5/BatchNorm2d_16/aten_batch_norm/add_1:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_5/BatchNorm2d_16/aten_batch_norm/add_1", axis=0) // ty=Tensor[(1, 2400, 2400, 64), float32]
  %27 = transpose(%26, framework_op_name="vgg16_bn_6/Sequential_5/BatchNorm2d_16/aten_batch_norm/transpose_1", output_tensors_name=["vgg16_bn_6/Sequential_5/BatchNorm2d_16/aten_batch_norm/transpose_1:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_5/BatchNorm2d_16/aten_batch_norm/transpose_1", axes=[0, 3, 1, 2]) // ty=Tensor[(1, 64, 2400, 2400), float32]
  %28 = nn.relu(%27, framework_op_name="vgg16_bn_6/Sequential_5/BatchNorm2d_16/aten_relu/Relu", output_tensors_name=["vgg16_bn_6/Sequential_5/BatchNorm2d_16/aten_relu/Relu:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_5/BatchNorm2d_16/aten_relu/Relu", axis=0) // ty=Tensor[(1, 64, 2400, 2400), float32]
  %29 = transpose(%28, framework_op_name="vgg16_bn_6/Sequential_5/MaxPool2d_18/aten_max_pool2d/transpose", output_tensors_name=["vgg16_bn_6/Sequential_5/MaxPool2d_18/aten_max_pool2d/transpose:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_5/MaxPool2d_18/aten_max_pool2d/transpose", axes=[0, 2, 3, 1]) // ty=Tensor[(1, 2400, 2400, 64), float32]
  %30 = nn.max_pool2d(%29, framework_op_name="vgg16_bn_6/Sequential_5/MaxPool2d_18/aten_max_pool2d/MaxPool2d", output_tensors_name=["vgg16_bn_6/Sequential_5/MaxPool2d_18/aten_max_pool2d/MaxPool2d:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_5/MaxPool2d_18/aten_max_pool2d/MaxPool2d", pool_size=[2, 2], pool_type="", strides=[2, 2], layout="NHWC") // ty=Tensor[(1, 1200, 1200, 64), float32]
  %31 = transpose(%30, framework_op_name="vgg16_bn_6/Sequential_5/MaxPool2d_18/aten_max_pool2d/transpose_1", output_tensors_name=["vgg16_bn_6/Sequential_5/MaxPool2d_18/aten_max_pool2d/transpose_1:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_5/MaxPool2d_18/aten_max_pool2d/transpose_1", axes=[0, 3, 1, 2]) // ty=Tensor[(1, 64, 1200, 1200), float32]
  %32 = transpose(%31, framework_op_name="vgg16_bn_6/Sequential_5/Conv2d_19/aten__convolution/transpose", output_tensors_name=["vgg16_bn_6/Sequential_5/Conv2d_19/aten__convolution/transpose:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_5/Conv2d_19/aten__convolution/transpose", axes=[0, 2, 3, 1]) // ty=Tensor[(1, 1200, 1200, 64), float32]
  %33 = nn.pad(%32, framework_op_name="vgg16_bn_6/Sequential_5/Conv2d_19/aten__convolution/Pad", output_tensors_name=["vgg16_bn_6/Sequential_5/Conv2d_19/aten__convolution/Pad:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_5/Conv2d_19/aten__convolution/Pad", pad_width=[[0, 0], [1, 1], [1, 1], [0, 0]]) // ty=Tensor[(1, 1202, 1202, 64), float32]
  %34 = nn.conv2d(%33, meta[relay.Constant][12] // ty=Tensor[(3, 3, 64, 128), float32], framework_op_name="vgg16_bn_6/Sequential_5/Conv2d_19/aten__convolution/Conv2D", output_tensors_name=["vgg16_bn_6/Sequential_5/Conv2d_19/aten__convolution/Conv2D:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_5/Conv2d_19/aten__convolution/Conv2D", channels=128, kernel_size=[3, 3], data_layout="NHWC", kernel_layout="HWIO") // ty=Tensor[(1, 1200, 1200, 128), float32]
  %35 = add(%34, meta[relay.Constant][13] // ty=Tensor[(128,), float32], framework_op_name="vgg16_bn_6/Sequential_5/Conv2d_19/aten__convolution/BiasAdd", output_tensors_name=["vgg16_bn_6/Sequential_5/Conv2d_19/aten__convolution/BiasAdd:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_5/Conv2d_19/aten__convolution/BiasAdd", axis=0) // ty=Tensor[(1, 1200, 1200, 128), float32]
  %36 = transpose(%35, framework_op_name="vgg16_bn_6/Sequential_5/Conv2d_19/aten__convolution/transpose_2", output_tensors_name=["vgg16_bn_6/Sequential_5/Conv2d_19/aten__convolution/transpose_2:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_5/Conv2d_19/aten__convolution/transpose_2", axes=[0, 3, 1, 2]) // ty=Tensor[(1, 128, 1200, 1200), float32]
  %37 = transpose(%36, framework_op_name="vgg16_bn_6/Sequential_5/BatchNorm2d_20/aten_batch_norm/transpose", output_tensors_name=["vgg16_bn_6/Sequential_5/BatchNorm2d_20/aten_batch_norm/transpose:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_5/BatchNorm2d_20/aten_batch_norm/transpose", axes=[0, 2, 3, 1]) // ty=Tensor[(1, 1200, 1200, 128), float32]
  %38 = subtract(%37, meta[relay.Constant][14] // ty=Tensor[(128,), float32], framework_op_name="vgg16_bn_6/Sequential_5/BatchNorm2d_20/aten_batch_norm/sub", output_tensors_name=["vgg16_bn_6/Sequential_5/BatchNorm2d_20/aten_batch_norm/sub:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_5/BatchNorm2d_20/aten_batch_norm/sub", axis=0) // ty=Tensor[(1, 1200, 1200, 128), float32]
  %39 = multiply(%38, meta[relay.Constant][15] // ty=Tensor[(128,), float32], framework_op_name="vgg16_bn_6/Sequential_5/BatchNorm2d_20/aten_batch_norm/truediv", output_tensors_name=["vgg16_bn_6/Sequential_5/BatchNorm2d_20/aten_batch_norm/truediv:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_5/BatchNorm2d_20/aten_batch_norm/truediv", axis=0) // ty=Tensor[(1, 1200, 1200, 128), float32]
  %40 = multiply(%39, meta[relay.Constant][16] // ty=Tensor[(128,), float32], framework_op_name="vgg16_bn_6/Sequential_5/BatchNorm2d_20/aten_batch_norm/mul", output_tensors_name=["vgg16_bn_6/Sequential_5/BatchNorm2d_20/aten_batch_norm/mul:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_5/BatchNorm2d_20/aten_batch_norm/mul", axis=0) // ty=Tensor[(1, 1200, 1200, 128), float32]
  %41 = add(%40, meta[relay.Constant][17] // ty=Tensor[(128,), float32], framework_op_name="vgg16_bn_6/Sequential_5/BatchNorm2d_20/aten_batch_norm/add_1", output_tensors_name=["vgg16_bn_6/Sequential_5/BatchNorm2d_20/aten_batch_norm/add_1:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_5/BatchNorm2d_20/aten_batch_norm/add_1", axis=0) // ty=Tensor[(1, 1200, 1200, 128), float32]
  %42 = transpose(%41, framework_op_name="vgg16_bn_6/Sequential_5/BatchNorm2d_20/aten_batch_norm/transpose_1", output_tensors_name=["vgg16_bn_6/Sequential_5/BatchNorm2d_20/aten_batch_norm/transpose_1:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_5/BatchNorm2d_20/aten_batch_norm/transpose_1", axes=[0, 3, 1, 2]) // ty=Tensor[(1, 128, 1200, 1200), float32]
  %43 = nn.relu(%42, framework_op_name="vgg16_bn_6/Sequential_5/BatchNorm2d_20/aten_relu/Relu", output_tensors_name=["vgg16_bn_6/Sequential_5/BatchNorm2d_20/aten_relu/Relu:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_5/BatchNorm2d_20/aten_relu/Relu", axis=0) // ty=Tensor[(1, 128, 1200, 1200), float32]
  %44 = transpose(%43, framework_op_name="vgg16_bn_6/Sequential_5/Conv2d_22/aten__convolution/transpose", output_tensors_name=["vgg16_bn_6/Sequential_5/Conv2d_22/aten__convolution/transpose:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_5/Conv2d_22/aten__convolution/transpose", axes=[0, 2, 3, 1]) // ty=Tensor[(1, 1200, 1200, 128), float32]
  %45 = nn.pad(%44, framework_op_name="vgg16_bn_6/Sequential_5/Conv2d_22/aten__convolution/Pad", output_tensors_name=["vgg16_bn_6/Sequential_5/Conv2d_22/aten__convolution/Pad:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_5/Conv2d_22/aten__convolution/Pad", pad_width=[[0, 0], [1, 1], [1, 1], [0, 0]]) // ty=Tensor[(1, 1202, 1202, 128), float32]
  %46 = nn.conv2d(%45, meta[relay.Constant][18] // ty=Tensor[(3, 3, 128, 128), float32], framework_op_name="vgg16_bn_6/Sequential_5/Conv2d_22/aten__convolution/Conv2D", output_tensors_name=["vgg16_bn_6/Sequential_5/Conv2d_22/aten__convolution/Conv2D:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_5/Conv2d_22/aten__convolution/Conv2D", channels=128, kernel_size=[3, 3], data_layout="NHWC", kernel_layout="HWIO") // ty=Tensor[(1, 1200, 1200, 128), float32]
  %47 = add(%46, meta[relay.Constant][19] // ty=Tensor[(128,), float32], framework_op_name="vgg16_bn_6/Sequential_5/Conv2d_22/aten__convolution/BiasAdd", output_tensors_name=["vgg16_bn_6/Sequential_5/Conv2d_22/aten__convolution/BiasAdd:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_5/Conv2d_22/aten__convolution/BiasAdd", axis=0) // ty=Tensor[(1, 1200, 1200, 128), float32]
  %48 = transpose(%47, framework_op_name="vgg16_bn_6/Sequential_5/Conv2d_22/aten__convolution/transpose_2", output_tensors_name=["vgg16_bn_6/Sequential_5/Conv2d_22/aten__convolution/transpose_2:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_5/Conv2d_22/aten__convolution/transpose_2", axes=[0, 3, 1, 2]) // ty=Tensor[(1, 128, 1200, 1200), float32]
  %49 = transpose(%48, framework_op_name="vgg16_bn_6/Sequential_5/BatchNorm2d_23/aten_batch_norm/transpose", output_tensors_name=["vgg16_bn_6/Sequential_5/BatchNorm2d_23/aten_batch_norm/transpose:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_5/BatchNorm2d_23/aten_batch_norm/transpose", axes=[0, 2, 3, 1]) // ty=Tensor[(1, 1200, 1200, 128), float32]
  %50 = subtract(%49, meta[relay.Constant][20] // ty=Tensor[(128,), float32], framework_op_name="vgg16_bn_6/Sequential_5/BatchNorm2d_23/aten_batch_norm/sub", output_tensors_name=["vgg16_bn_6/Sequential_5/BatchNorm2d_23/aten_batch_norm/sub:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_5/BatchNorm2d_23/aten_batch_norm/sub", axis=0) // ty=Tensor[(1, 1200, 1200, 128), float32]
  %51 = multiply(%50, meta[relay.Constant][21] // ty=Tensor[(128,), float32], framework_op_name="vgg16_bn_6/Sequential_5/BatchNorm2d_23/aten_batch_norm/truediv", output_tensors_name=["vgg16_bn_6/Sequential_5/BatchNorm2d_23/aten_batch_norm/truediv:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_5/BatchNorm2d_23/aten_batch_norm/truediv", axis=0) // ty=Tensor[(1, 1200, 1200, 128), float32]
  %52 = multiply(%51, meta[relay.Constant][22] // ty=Tensor[(128,), float32], framework_op_name="vgg16_bn_6/Sequential_5/BatchNorm2d_23/aten_batch_norm/mul", output_tensors_name=["vgg16_bn_6/Sequential_5/BatchNorm2d_23/aten_batch_norm/mul:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_5/BatchNorm2d_23/aten_batch_norm/mul", axis=0) // ty=Tensor[(1, 1200, 1200, 128), float32]
  %53 = add(%52, meta[relay.Constant][23] // ty=Tensor[(128,), float32], framework_op_name="vgg16_bn_6/Sequential_5/BatchNorm2d_23/aten_batch_norm/add_1", output_tensors_name=["vgg16_bn_6/Sequential_5/BatchNorm2d_23/aten_batch_norm/add_1:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_5/BatchNorm2d_23/aten_batch_norm/add_1", axis=0) // ty=Tensor[(1, 1200, 1200, 128), float32]
  %54 = transpose(%53, framework_op_name="vgg16_bn_6/Sequential_5/BatchNorm2d_23/aten_batch_norm/transpose_1", output_tensors_name=["vgg16_bn_6/Sequential_5/BatchNorm2d_23/aten_batch_norm/transpose_1:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_5/BatchNorm2d_23/aten_batch_norm/transpose_1", axes=[0, 3, 1, 2]) // ty=Tensor[(1, 128, 1200, 1200), float32]
  %55 = nn.relu(%54, framework_op_name="vgg16_bn_6/Sequential_5/BatchNorm2d_23/aten_relu/Relu", output_tensors_name=["vgg16_bn_6/Sequential_5/BatchNorm2d_23/aten_relu/Relu:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_5/BatchNorm2d_23/aten_relu/Relu", axis=0) // ty=Tensor[(1, 128, 1200, 1200), float32]
  %56 = transpose(%55, framework_op_name="vgg16_bn_6/Sequential_6/MaxPool2d_8/aten_max_pool2d/transpose", output_tensors_name=["vgg16_bn_6/Sequential_6/MaxPool2d_8/aten_max_pool2d/transpose:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_6/MaxPool2d_8/aten_max_pool2d/transpose", axes=[0, 2, 3, 1]) // ty=Tensor[(1, 1200, 1200, 128), float32]
  %57 = nn.max_pool2d(%56, framework_op_name="vgg16_bn_6/Sequential_6/MaxPool2d_8/aten_max_pool2d/MaxPool2d", output_tensors_name=["vgg16_bn_6/Sequential_6/MaxPool2d_8/aten_max_pool2d/MaxPool2d:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_6/MaxPool2d_8/aten_max_pool2d/MaxPool2d", pool_size=[2, 2], pool_type="", strides=[2, 2], layout="NHWC") // ty=Tensor[(1, 600, 600, 128), float32]
  %58 = transpose(%57, framework_op_name="vgg16_bn_6/Sequential_6/MaxPool2d_8/aten_max_pool2d/transpose_1", output_tensors_name=["vgg16_bn_6/Sequential_6/MaxPool2d_8/aten_max_pool2d/transpose_1:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_6/MaxPool2d_8/aten_max_pool2d/transpose_1", axes=[0, 3, 1, 2]) // ty=Tensor[(1, 128, 600, 600), float32]
  %59 = transpose(%58, framework_op_name="vgg16_bn_6/Sequential_6/Conv2d_9/aten__convolution/transpose", output_tensors_name=["vgg16_bn_6/Sequential_6/Conv2d_9/aten__convolution/transpose:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_6/Conv2d_9/aten__convolution/transpose", axes=[0, 2, 3, 1]) // ty=Tensor[(1, 600, 600, 128), float32]
  %60 = nn.pad(%59, framework_op_name="vgg16_bn_6/Sequential_6/Conv2d_9/aten__convolution/Pad", output_tensors_name=["vgg16_bn_6/Sequential_6/Conv2d_9/aten__convolution/Pad:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_6/Conv2d_9/aten__convolution/Pad", pad_width=[[0, 0], [1, 1], [1, 1], [0, 0]]) // ty=Tensor[(1, 602, 602, 128), float32]
  %61 = nn.conv2d(%60, meta[relay.Constant][24] // ty=Tensor[(3, 3, 128, 256), float32], framework_op_name="vgg16_bn_6/Sequential_6/Conv2d_9/aten__convolution/Conv2D", output_tensors_name=["vgg16_bn_6/Sequential_6/Conv2d_9/aten__convolution/Conv2D:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_6/Conv2d_9/aten__convolution/Conv2D", channels=256, kernel_size=[3, 3], data_layout="NHWC", kernel_layout="HWIO") // ty=Tensor[(1, 600, 600, 256), float32]
  %62 = add(%61, meta[relay.Constant][25] // ty=Tensor[(256,), float32], framework_op_name="vgg16_bn_6/Sequential_6/Conv2d_9/aten__convolution/BiasAdd", output_tensors_name=["vgg16_bn_6/Sequential_6/Conv2d_9/aten__convolution/BiasAdd:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_6/Conv2d_9/aten__convolution/BiasAdd", axis=0) // ty=Tensor[(1, 600, 600, 256), float32]
  %63 = transpose(%62, framework_op_name="vgg16_bn_6/Sequential_6/Conv2d_9/aten__convolution/transpose_2", output_tensors_name=["vgg16_bn_6/Sequential_6/Conv2d_9/aten__convolution/transpose_2:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_6/Conv2d_9/aten__convolution/transpose_2", axes=[0, 3, 1, 2]) // ty=Tensor[(1, 256, 600, 600), float32]
  %64 = transpose(%63, framework_op_name="vgg16_bn_6/Sequential_6/BatchNorm2d_10/aten_batch_norm/transpose", output_tensors_name=["vgg16_bn_6/Sequential_6/BatchNorm2d_10/aten_batch_norm/transpose:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_6/BatchNorm2d_10/aten_batch_norm/transpose", axes=[0, 2, 3, 1]) // ty=Tensor[(1, 600, 600, 256), float32]
  %65 = subtract(%64, meta[relay.Constant][26] // ty=Tensor[(256,), float32], framework_op_name="vgg16_bn_6/Sequential_6/BatchNorm2d_10/aten_batch_norm/sub", output_tensors_name=["vgg16_bn_6/Sequential_6/BatchNorm2d_10/aten_batch_norm/sub:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_6/BatchNorm2d_10/aten_batch_norm/sub", axis=0) // ty=Tensor[(1, 600, 600, 256), float32]
  %66 = multiply(%65, meta[relay.Constant][27] // ty=Tensor[(256,), float32], framework_op_name="vgg16_bn_6/Sequential_6/BatchNorm2d_10/aten_batch_norm/truediv", output_tensors_name=["vgg16_bn_6/Sequential_6/BatchNorm2d_10/aten_batch_norm/truediv:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_6/BatchNorm2d_10/aten_batch_norm/truediv", axis=0) // ty=Tensor[(1, 600, 600, 256), float32]
  %67 = multiply(%66, meta[relay.Constant][28] // ty=Tensor[(256,), float32], framework_op_name="vgg16_bn_6/Sequential_6/BatchNorm2d_10/aten_batch_norm/mul", output_tensors_name=["vgg16_bn_6/Sequential_6/BatchNorm2d_10/aten_batch_norm/mul:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_6/BatchNorm2d_10/aten_batch_norm/mul", axis=0) // ty=Tensor[(1, 600, 600, 256), float32]
  %68 = add(%67, meta[relay.Constant][29] // ty=Tensor[(256,), float32], framework_op_name="vgg16_bn_6/Sequential_6/BatchNorm2d_10/aten_batch_norm/add_1", output_tensors_name=["vgg16_bn_6/Sequential_6/BatchNorm2d_10/aten_batch_norm/add_1:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_6/BatchNorm2d_10/aten_batch_norm/add_1", axis=0) // ty=Tensor[(1, 600, 600, 256), float32]
  %69 = transpose(%68, framework_op_name="vgg16_bn_6/Sequential_6/BatchNorm2d_10/aten_batch_norm/transpose_1", output_tensors_name=["vgg16_bn_6/Sequential_6/BatchNorm2d_10/aten_batch_norm/transpose_1:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_6/BatchNorm2d_10/aten_batch_norm/transpose_1", axes=[0, 3, 1, 2]) // ty=Tensor[(1, 256, 600, 600), float32]
  %70 = nn.relu(%69, framework_op_name="vgg16_bn_6/Sequential_6/BatchNorm2d_10/aten_relu/Relu", output_tensors_name=["vgg16_bn_6/Sequential_6/BatchNorm2d_10/aten_relu/Relu:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_6/BatchNorm2d_10/aten_relu/Relu", axis=0) // ty=Tensor[(1, 256, 600, 600), float32]
  %71 = transpose(%70, framework_op_name="vgg16_bn_6/Sequential_6/Conv2d_12/aten__convolution/transpose", output_tensors_name=["vgg16_bn_6/Sequential_6/Conv2d_12/aten__convolution/transpose:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_6/Conv2d_12/aten__convolution/transpose", axes=[0, 2, 3, 1]) // ty=Tensor[(1, 600, 600, 256), float32]
  %72 = nn.pad(%71, framework_op_name="vgg16_bn_6/Sequential_6/Conv2d_12/aten__convolution/Pad", output_tensors_name=["vgg16_bn_6/Sequential_6/Conv2d_12/aten__convolution/Pad:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_6/Conv2d_12/aten__convolution/Pad", pad_width=[[0, 0], [1, 1], [1, 1], [0, 0]]) // ty=Tensor[(1, 602, 602, 256), float32]
  %73 = nn.conv2d(%72, meta[relay.Constant][30] // ty=Tensor[(3, 3, 256, 256), float32], framework_op_name="vgg16_bn_6/Sequential_6/Conv2d_12/aten__convolution/Conv2D", output_tensors_name=["vgg16_bn_6/Sequential_6/Conv2d_12/aten__convolution/Conv2D:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_6/Conv2d_12/aten__convolution/Conv2D", channels=256, kernel_size=[3, 3], data_layout="NHWC", kernel_layout="HWIO") // ty=Tensor[(1, 600, 600, 256), float32]
  %74 = add(%73, meta[relay.Constant][31] // ty=Tensor[(256,), float32], framework_op_name="vgg16_bn_6/Sequential_6/Conv2d_12/aten__convolution/BiasAdd", output_tensors_name=["vgg16_bn_6/Sequential_6/Conv2d_12/aten__convolution/BiasAdd:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_6/Conv2d_12/aten__convolution/BiasAdd", axis=0) // ty=Tensor[(1, 600, 600, 256), float32]
  %75 = transpose(%74, framework_op_name="vgg16_bn_6/Sequential_6/Conv2d_12/aten__convolution/transpose_2", output_tensors_name=["vgg16_bn_6/Sequential_6/Conv2d_12/aten__convolution/transpose_2:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_6/Conv2d_12/aten__convolution/transpose_2", axes=[0, 3, 1, 2]) // ty=Tensor[(1, 256, 600, 600), float32]
  %76 = transpose(%75, framework_op_name="vgg16_bn_6/Sequential_6/BatchNorm2d_13/aten_batch_norm/transpose", output_tensors_name=["vgg16_bn_6/Sequential_6/BatchNorm2d_13/aten_batch_norm/transpose:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_6/BatchNorm2d_13/aten_batch_norm/transpose", axes=[0, 2, 3, 1]) // ty=Tensor[(1, 600, 600, 256), float32]
  %77 = subtract(%76, meta[relay.Constant][32] // ty=Tensor[(256,), float32], framework_op_name="vgg16_bn_6/Sequential_6/BatchNorm2d_13/aten_batch_norm/sub", output_tensors_name=["vgg16_bn_6/Sequential_6/BatchNorm2d_13/aten_batch_norm/sub:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_6/BatchNorm2d_13/aten_batch_norm/sub", axis=0) // ty=Tensor[(1, 600, 600, 256), float32]
  %78 = multiply(%77, meta[relay.Constant][33] // ty=Tensor[(256,), float32], framework_op_name="vgg16_bn_6/Sequential_6/BatchNorm2d_13/aten_batch_norm/truediv", output_tensors_name=["vgg16_bn_6/Sequential_6/BatchNorm2d_13/aten_batch_norm/truediv:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_6/BatchNorm2d_13/aten_batch_norm/truediv", axis=0) // ty=Tensor[(1, 600, 600, 256), float32]
  %79 = multiply(%78, meta[relay.Constant][34] // ty=Tensor[(256,), float32], framework_op_name="vgg16_bn_6/Sequential_6/BatchNorm2d_13/aten_batch_norm/mul", output_tensors_name=["vgg16_bn_6/Sequential_6/BatchNorm2d_13/aten_batch_norm/mul:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_6/BatchNorm2d_13/aten_batch_norm/mul", axis=0) // ty=Tensor[(1, 600, 600, 256), float32]
  %80 = add(%79, meta[relay.Constant][35] // ty=Tensor[(256,), float32], framework_op_name="vgg16_bn_6/Sequential_6/BatchNorm2d_13/aten_batch_norm/add_1", output_tensors_name=["vgg16_bn_6/Sequential_6/BatchNorm2d_13/aten_batch_norm/add_1:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_6/BatchNorm2d_13/aten_batch_norm/add_1", axis=0) // ty=Tensor[(1, 600, 600, 256), float32]
  %81 = transpose(%80, framework_op_name="vgg16_bn_6/Sequential_6/BatchNorm2d_13/aten_batch_norm/transpose_1", output_tensors_name=["vgg16_bn_6/Sequential_6/BatchNorm2d_13/aten_batch_norm/transpose_1:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_6/BatchNorm2d_13/aten_batch_norm/transpose_1", axes=[0, 3, 1, 2]) // ty=Tensor[(1, 256, 600, 600), float32]
  %82 = nn.relu(%81, framework_op_name="vgg16_bn_6/Sequential_6/BatchNorm2d_13/aten_relu/Relu", output_tensors_name=["vgg16_bn_6/Sequential_6/BatchNorm2d_13/aten_relu/Relu:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_6/BatchNorm2d_13/aten_relu/Relu", axis=0) // ty=Tensor[(1, 256, 600, 600), float32]
  %83 = transpose(%82, framework_op_name="vgg16_bn_6/Sequential_8/Conv2d_11/aten__convolution/transpose", output_tensors_name=["vgg16_bn_6/Sequential_8/Conv2d_11/aten__convolution/transpose:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_8/Conv2d_11/aten__convolution/transpose", axes=[0, 2, 3, 1]) // ty=Tensor[(1, 600, 600, 256), float32]
  %84 = nn.pad(%83, framework_op_name="vgg16_bn_6/Sequential_8/Conv2d_11/aten__convolution/Pad", output_tensors_name=["vgg16_bn_6/Sequential_8/Conv2d_11/aten__convolution/Pad:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_8/Conv2d_11/aten__convolution/Pad", pad_width=[[0, 0], [1, 1], [1, 1], [0, 0]]) // ty=Tensor[(1, 602, 602, 256), float32]
  %85 = nn.conv2d(%84, meta[relay.Constant][36] // ty=Tensor[(3, 3, 256, 256), float32], framework_op_name="vgg16_bn_6/Sequential_8/Conv2d_11/aten__convolution/Conv2D", output_tensors_name=["vgg16_bn_6/Sequential_8/Conv2d_11/aten__convolution/Conv2D:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_8/Conv2d_11/aten__convolution/Conv2D", channels=256, kernel_size=[3, 3], data_layout="NHWC", kernel_layout="HWIO") // ty=Tensor[(1, 600, 600, 256), float32]
  %86 = add(%85, meta[relay.Constant][37] // ty=Tensor[(256,), float32], framework_op_name="vgg16_bn_6/Sequential_8/Conv2d_11/aten__convolution/BiasAdd", output_tensors_name=["vgg16_bn_6/Sequential_8/Conv2d_11/aten__convolution/BiasAdd:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_8/Conv2d_11/aten__convolution/BiasAdd", axis=0) // ty=Tensor[(1, 600, 600, 256), float32]
  %87 = transpose(%86, framework_op_name="vgg16_bn_6/Sequential_8/Conv2d_11/aten__convolution/transpose_2", output_tensors_name=["vgg16_bn_6/Sequential_8/Conv2d_11/aten__convolution/transpose_2:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_8/Conv2d_11/aten__convolution/transpose_2", axes=[0, 3, 1, 2]) // ty=Tensor[(1, 256, 600, 600), float32]
  %88 = transpose(%87, framework_op_name="vgg16_bn_6/Sequential_8/BatchNorm2d_12/aten_batch_norm/transpose", output_tensors_name=["vgg16_bn_6/Sequential_8/BatchNorm2d_12/aten_batch_norm/transpose:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_8/BatchNorm2d_12/aten_batch_norm/transpose", axes=[0, 2, 3, 1]) // ty=Tensor[(1, 600, 600, 256), float32]
  %89 = subtract(%88, meta[relay.Constant][38] // ty=Tensor[(256,), float32], framework_op_name="vgg16_bn_6/Sequential_8/BatchNorm2d_12/aten_batch_norm/sub", output_tensors_name=["vgg16_bn_6/Sequential_8/BatchNorm2d_12/aten_batch_norm/sub:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_8/BatchNorm2d_12/aten_batch_norm/sub", axis=0) // ty=Tensor[(1, 600, 600, 256), float32]
  %90 = multiply(%89, meta[relay.Constant][39] // ty=Tensor[(256,), float32], framework_op_name="vgg16_bn_6/Sequential_8/BatchNorm2d_12/aten_batch_norm/truediv", output_tensors_name=["vgg16_bn_6/Sequential_8/BatchNorm2d_12/aten_batch_norm/truediv:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_8/BatchNorm2d_12/aten_batch_norm/truediv", axis=0) // ty=Tensor[(1, 600, 600, 256), float32]
  %91 = multiply(%90, meta[relay.Constant][40] // ty=Tensor[(256,), float32], framework_op_name="vgg16_bn_6/Sequential_8/BatchNorm2d_12/aten_batch_norm/mul", output_tensors_name=["vgg16_bn_6/Sequential_8/BatchNorm2d_12/aten_batch_norm/mul:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_8/BatchNorm2d_12/aten_batch_norm/mul", axis=0) // ty=Tensor[(1, 600, 600, 256), float32]
  %92 = add(%91, meta[relay.Constant][41] // ty=Tensor[(256,), float32], framework_op_name="vgg16_bn_6/Sequential_8/BatchNorm2d_12/aten_batch_norm/add_1", output_tensors_name=["vgg16_bn_6/Sequential_8/BatchNorm2d_12/aten_batch_norm/add_1:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_8/BatchNorm2d_12/aten_batch_norm/add_1", axis=0) // ty=Tensor[(1, 600, 600, 256), float32]
  %93 = transpose(%92, framework_op_name="vgg16_bn_6/Sequential_8/BatchNorm2d_12/aten_batch_norm/transpose_1", output_tensors_name=["vgg16_bn_6/Sequential_8/BatchNorm2d_12/aten_batch_norm/transpose_1:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_8/BatchNorm2d_12/aten_batch_norm/transpose_1", axes=[0, 3, 1, 2]) // ty=Tensor[(1, 256, 600, 600), float32]
  %94 = nn.relu(%93, framework_op_name="vgg16_bn_6/Sequential_8/BatchNorm2d_12/aten_relu/Relu", output_tensors_name=["vgg16_bn_6/Sequential_8/BatchNorm2d_12/aten_relu/Relu:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_8/BatchNorm2d_12/aten_relu/Relu", axis=0) // ty=Tensor[(1, 256, 600, 600), float32]
  %95 = transpose(%94, framework_op_name="vgg16_bn_6/Sequential_8/MaxPool2d_14/aten_max_pool2d/transpose", output_tensors_name=["vgg16_bn_6/Sequential_8/MaxPool2d_14/aten_max_pool2d/transpose:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_8/MaxPool2d_14/aten_max_pool2d/transpose", axes=[0, 2, 3, 1]) // ty=Tensor[(1, 600, 600, 256), float32]
  %96 = nn.max_pool2d(%95, framework_op_name="vgg16_bn_6/Sequential_8/MaxPool2d_14/aten_max_pool2d/MaxPool2d", output_tensors_name=["vgg16_bn_6/Sequential_8/MaxPool2d_14/aten_max_pool2d/MaxPool2d:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_8/MaxPool2d_14/aten_max_pool2d/MaxPool2d", pool_size=[2, 2], pool_type="", strides=[2, 2], layout="NHWC") // ty=Tensor[(1, 300, 300, 256), float32]
  %97 = transpose(%96, framework_op_name="vgg16_bn_6/Sequential_8/MaxPool2d_14/aten_max_pool2d/transpose_1", output_tensors_name=["vgg16_bn_6/Sequential_8/MaxPool2d_14/aten_max_pool2d/transpose_1:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_8/MaxPool2d_14/aten_max_pool2d/transpose_1", axes=[0, 3, 1, 2]) // ty=Tensor[(1, 256, 300, 300), float32]
  %98 = transpose(%97, framework_op_name="vgg16_bn_6/Sequential_8/Conv2d_15/aten__convolution/transpose", output_tensors_name=["vgg16_bn_6/Sequential_8/Conv2d_15/aten__convolution/transpose:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_8/Conv2d_15/aten__convolution/transpose", axes=[0, 2, 3, 1]) // ty=Tensor[(1, 300, 300, 256), float32]
  %99 = nn.pad(%98, framework_op_name="vgg16_bn_6/Sequential_8/Conv2d_15/aten__convolution/Pad", output_tensors_name=["vgg16_bn_6/Sequential_8/Conv2d_15/aten__convolution/Pad:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_8/Conv2d_15/aten__convolution/Pad", pad_width=[[0, 0], [1, 1], [1, 1], [0, 0]]) // ty=Tensor[(1, 302, 302, 256), float32]
  %100 = nn.conv2d(%99, meta[relay.Constant][42] // ty=Tensor[(3, 3, 256, 512), float32], framework_op_name="vgg16_bn_6/Sequential_8/Conv2d_15/aten__convolution/Conv2D", output_tensors_name=["vgg16_bn_6/Sequential_8/Conv2d_15/aten__convolution/Conv2D:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_8/Conv2d_15/aten__convolution/Conv2D", channels=512, kernel_size=[3, 3], data_layout="NHWC", kernel_layout="HWIO") // ty=Tensor[(1, 300, 300, 512), float32]
  %101 = add(%100, meta[relay.Constant][43] // ty=Tensor[(512,), float32], framework_op_name="vgg16_bn_6/Sequential_8/Conv2d_15/aten__convolution/BiasAdd", output_tensors_name=["vgg16_bn_6/Sequential_8/Conv2d_15/aten__convolution/BiasAdd:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_8/Conv2d_15/aten__convolution/BiasAdd", axis=0) // ty=Tensor[(1, 300, 300, 512), float32]
  %102 = transpose(%101, framework_op_name="vgg16_bn_6/Sequential_8/Conv2d_15/aten__convolution/transpose_2", output_tensors_name=["vgg16_bn_6/Sequential_8/Conv2d_15/aten__convolution/transpose_2:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_8/Conv2d_15/aten__convolution/transpose_2", axes=[0, 3, 1, 2]) // ty=Tensor[(1, 512, 300, 300), float32]
  %103 = transpose(%102, framework_op_name="vgg16_bn_6/Sequential_8/BatchNorm2d_16/aten_batch_norm/transpose", output_tensors_name=["vgg16_bn_6/Sequential_8/BatchNorm2d_16/aten_batch_norm/transpose:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_8/BatchNorm2d_16/aten_batch_norm/transpose", axes=[0, 2, 3, 1]) // ty=Tensor[(1, 300, 300, 512), float32]
  %104 = subtract(%103, meta[relay.Constant][44] // ty=Tensor[(512,), float32], framework_op_name="vgg16_bn_6/Sequential_8/BatchNorm2d_16/aten_batch_norm/sub", output_tensors_name=["vgg16_bn_6/Sequential_8/BatchNorm2d_16/aten_batch_norm/sub:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_8/BatchNorm2d_16/aten_batch_norm/sub", axis=0) // ty=Tensor[(1, 300, 300, 512), float32]
  %105 = multiply(%104, meta[relay.Constant][45] // ty=Tensor[(512,), float32], framework_op_name="vgg16_bn_6/Sequential_8/BatchNorm2d_16/aten_batch_norm/truediv", output_tensors_name=["vgg16_bn_6/Sequential_8/BatchNorm2d_16/aten_batch_norm/truediv:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_8/BatchNorm2d_16/aten_batch_norm/truediv", axis=0) // ty=Tensor[(1, 300, 300, 512), float32]
  %106 = multiply(%105, meta[relay.Constant][46] // ty=Tensor[(512,), float32], framework_op_name="vgg16_bn_6/Sequential_8/BatchNorm2d_16/aten_batch_norm/mul", output_tensors_name=["vgg16_bn_6/Sequential_8/BatchNorm2d_16/aten_batch_norm/mul:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_8/BatchNorm2d_16/aten_batch_norm/mul", axis=0) // ty=Tensor[(1, 300, 300, 512), float32]
  %107 = add(%106, meta[relay.Constant][47] // ty=Tensor[(512,), float32], framework_op_name="vgg16_bn_6/Sequential_8/BatchNorm2d_16/aten_batch_norm/add_1", output_tensors_name=["vgg16_bn_6/Sequential_8/BatchNorm2d_16/aten_batch_norm/add_1:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_8/BatchNorm2d_16/aten_batch_norm/add_1", axis=0) // ty=Tensor[(1, 300, 300, 512), float32]
  %108 = transpose(%107, framework_op_name="vgg16_bn_6/Sequential_8/BatchNorm2d_16/aten_batch_norm/transpose_1", output_tensors_name=["vgg16_bn_6/Sequential_8/BatchNorm2d_16/aten_batch_norm/transpose_1:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_8/BatchNorm2d_16/aten_batch_norm/transpose_1", axes=[0, 3, 1, 2]) // ty=Tensor[(1, 512, 300, 300), float32]
  %109 = nn.relu(%108, framework_op_name="vgg16_bn_6/Sequential_8/BatchNorm2d_16/aten_relu/Relu", output_tensors_name=["vgg16_bn_6/Sequential_8/BatchNorm2d_16/aten_relu/Relu:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_8/BatchNorm2d_16/aten_relu/Relu", axis=0) // ty=Tensor[(1, 512, 300, 300), float32]
  %110 = transpose(%109, framework_op_name="vgg16_bn_6/Sequential_8/Conv2d_18/aten__convolution/transpose", output_tensors_name=["vgg16_bn_6/Sequential_8/Conv2d_18/aten__convolution/transpose:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_8/Conv2d_18/aten__convolution/transpose", axes=[0, 2, 3, 1]) // ty=Tensor[(1, 300, 300, 512), float32]
  %111 = nn.pad(%110, framework_op_name="vgg16_bn_6/Sequential_8/Conv2d_18/aten__convolution/Pad", output_tensors_name=["vgg16_bn_6/Sequential_8/Conv2d_18/aten__convolution/Pad:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_8/Conv2d_18/aten__convolution/Pad", pad_width=[[0, 0], [1, 1], [1, 1], [0, 0]]) // ty=Tensor[(1, 302, 302, 512), float32]
  %112 = nn.conv2d(%111, meta[relay.Constant][48] // ty=Tensor[(3, 3, 512, 512), float32], framework_op_name="vgg16_bn_6/Sequential_8/Conv2d_18/aten__convolution/Conv2D", output_tensors_name=["vgg16_bn_6/Sequential_8/Conv2d_18/aten__convolution/Conv2D:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_8/Conv2d_18/aten__convolution/Conv2D", channels=512, kernel_size=[3, 3], data_layout="NHWC", kernel_layout="HWIO") // ty=Tensor[(1, 300, 300, 512), float32]
  %113 = add(%112, meta[relay.Constant][49] // ty=Tensor[(512,), float32], framework_op_name="vgg16_bn_6/Sequential_8/Conv2d_18/aten__convolution/BiasAdd", output_tensors_name=["vgg16_bn_6/Sequential_8/Conv2d_18/aten__convolution/BiasAdd:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_8/Conv2d_18/aten__convolution/BiasAdd", axis=0) // ty=Tensor[(1, 300, 300, 512), float32]
  %114 = transpose(%113, framework_op_name="vgg16_bn_6/Sequential_8/Conv2d_18/aten__convolution/transpose_2", output_tensors_name=["vgg16_bn_6/Sequential_8/Conv2d_18/aten__convolution/transpose_2:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_8/Conv2d_18/aten__convolution/transpose_2", axes=[0, 3, 1, 2]) // ty=Tensor[(1, 512, 300, 300), float32]
  %115 = transpose(%114, framework_op_name="vgg16_bn_6/Sequential_8/BatchNorm2d_19/aten_batch_norm/transpose", output_tensors_name=["vgg16_bn_6/Sequential_8/BatchNorm2d_19/aten_batch_norm/transpose:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_8/BatchNorm2d_19/aten_batch_norm/transpose", axes=[0, 2, 3, 1]) // ty=Tensor[(1, 300, 300, 512), float32]
  %116 = subtract(%115, meta[relay.Constant][50] // ty=Tensor[(512,), float32], framework_op_name="vgg16_bn_6/Sequential_8/BatchNorm2d_19/aten_batch_norm/sub", output_tensors_name=["vgg16_bn_6/Sequential_8/BatchNorm2d_19/aten_batch_norm/sub:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_8/BatchNorm2d_19/aten_batch_norm/sub", axis=0) // ty=Tensor[(1, 300, 300, 512), float32]
  %117 = multiply(%116, meta[relay.Constant][51] // ty=Tensor[(512,), float32], framework_op_name="vgg16_bn_6/Sequential_8/BatchNorm2d_19/aten_batch_norm/truediv", output_tensors_name=["vgg16_bn_6/Sequential_8/BatchNorm2d_19/aten_batch_norm/truediv:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_8/BatchNorm2d_19/aten_batch_norm/truediv", axis=0) // ty=Tensor[(1, 300, 300, 512), float32]
  %118 = multiply(%117, meta[relay.Constant][52] // ty=Tensor[(512,), float32], framework_op_name="vgg16_bn_6/Sequential_8/BatchNorm2d_19/aten_batch_norm/mul", output_tensors_name=["vgg16_bn_6/Sequential_8/BatchNorm2d_19/aten_batch_norm/mul:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_8/BatchNorm2d_19/aten_batch_norm/mul", axis=0) // ty=Tensor[(1, 300, 300, 512), float32]
  %119 = add(%118, meta[relay.Constant][53] // ty=Tensor[(512,), float32], framework_op_name="vgg16_bn_6/Sequential_8/BatchNorm2d_19/aten_batch_norm/add_1", output_tensors_name=["vgg16_bn_6/Sequential_8/BatchNorm2d_19/aten_batch_norm/add_1:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_8/BatchNorm2d_19/aten_batch_norm/add_1", axis=0) // ty=Tensor[(1, 300, 300, 512), float32]
  %120 = transpose(%119, framework_op_name="vgg16_bn_6/Sequential_8/BatchNorm2d_19/aten_batch_norm/transpose_1", output_tensors_name=["vgg16_bn_6/Sequential_8/BatchNorm2d_19/aten_batch_norm/transpose_1:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_8/BatchNorm2d_19/aten_batch_norm/transpose_1", axes=[0, 3, 1, 2]) // ty=Tensor[(1, 512, 300, 300), float32]
  %121 = nn.relu(%120, framework_op_name="vgg16_bn_6/Sequential_8/BatchNorm2d_19/aten_relu/Relu", output_tensors_name=["vgg16_bn_6/Sequential_8/BatchNorm2d_19/aten_relu/Relu:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_8/BatchNorm2d_19/aten_relu/Relu", axis=0) // ty=Tensor[(1, 512, 300, 300), float32]
  %122 = transpose(%121, framework_op_name="vgg16_bn_6/Sequential_10/Conv2d_11/aten__convolution/transpose", output_tensors_name=["vgg16_bn_6/Sequential_10/Conv2d_11/aten__convolution/transpose:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_10/Conv2d_11/aten__convolution/transpose", axes=[0, 2, 3, 1]) // ty=Tensor[(1, 300, 300, 512), float32]
  %123 = nn.pad(%122, framework_op_name="vgg16_bn_6/Sequential_10/Conv2d_11/aten__convolution/Pad", output_tensors_name=["vgg16_bn_6/Sequential_10/Conv2d_11/aten__convolution/Pad:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_10/Conv2d_11/aten__convolution/Pad", pad_width=[[0, 0], [1, 1], [1, 1], [0, 0]]) // ty=Tensor[(1, 302, 302, 512), float32]
  %124 = nn.conv2d(%123, meta[relay.Constant][54] // ty=Tensor[(3, 3, 512, 512), float32], framework_op_name="vgg16_bn_6/Sequential_10/Conv2d_11/aten__convolution/Conv2D", output_tensors_name=["vgg16_bn_6/Sequential_10/Conv2d_11/aten__convolution/Conv2D:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_10/Conv2d_11/aten__convolution/Conv2D", channels=512, kernel_size=[3, 3], data_layout="NHWC", kernel_layout="HWIO") // ty=Tensor[(1, 300, 300, 512), float32]
  %125 = add(%124, meta[relay.Constant][55] // ty=Tensor[(512,), float32], framework_op_name="vgg16_bn_6/Sequential_10/Conv2d_11/aten__convolution/BiasAdd", output_tensors_name=["vgg16_bn_6/Sequential_10/Conv2d_11/aten__convolution/BiasAdd:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_10/Conv2d_11/aten__convolution/BiasAdd", axis=0) // ty=Tensor[(1, 300, 300, 512), float32]
  %126 = transpose(%125, framework_op_name="vgg16_bn_6/Sequential_10/Conv2d_11/aten__convolution/transpose_2", output_tensors_name=["vgg16_bn_6/Sequential_10/Conv2d_11/aten__convolution/transpose_2:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_10/Conv2d_11/aten__convolution/transpose_2", axes=[0, 3, 1, 2]) // ty=Tensor[(1, 512, 300, 300), float32]
  %127 = transpose(%126, framework_op_name="vgg16_bn_6/Sequential_10/BatchNorm2d_12/aten_batch_norm/transpose", output_tensors_name=["vgg16_bn_6/Sequential_10/BatchNorm2d_12/aten_batch_norm/transpose:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_10/BatchNorm2d_12/aten_batch_norm/transpose", axes=[0, 2, 3, 1]) // ty=Tensor[(1, 300, 300, 512), float32]
  %128 = subtract(%127, meta[relay.Constant][56] // ty=Tensor[(512,), float32], framework_op_name="vgg16_bn_6/Sequential_10/BatchNorm2d_12/aten_batch_norm/sub", output_tensors_name=["vgg16_bn_6/Sequential_10/BatchNorm2d_12/aten_batch_norm/sub:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_10/BatchNorm2d_12/aten_batch_norm/sub", axis=0) // ty=Tensor[(1, 300, 300, 512), float32]
  %129 = multiply(%128, meta[relay.Constant][57] // ty=Tensor[(512,), float32], framework_op_name="vgg16_bn_6/Sequential_10/BatchNorm2d_12/aten_batch_norm/truediv", output_tensors_name=["vgg16_bn_6/Sequential_10/BatchNorm2d_12/aten_batch_norm/truediv:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_10/BatchNorm2d_12/aten_batch_norm/truediv", axis=0) // ty=Tensor[(1, 300, 300, 512), float32]
  %130 = multiply(%129, meta[relay.Constant][58] // ty=Tensor[(512,), float32], framework_op_name="vgg16_bn_6/Sequential_10/BatchNorm2d_12/aten_batch_norm/mul", output_tensors_name=["vgg16_bn_6/Sequential_10/BatchNorm2d_12/aten_batch_norm/mul:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_10/BatchNorm2d_12/aten_batch_norm/mul", axis=0) // ty=Tensor[(1, 300, 300, 512), float32]
  %131 = add(%130, meta[relay.Constant][59] // ty=Tensor[(512,), float32], framework_op_name="vgg16_bn_6/Sequential_10/BatchNorm2d_12/aten_batch_norm/add_1", output_tensors_name=["vgg16_bn_6/Sequential_10/BatchNorm2d_12/aten_batch_norm/add_1:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_10/BatchNorm2d_12/aten_batch_norm/add_1", axis=0) // ty=Tensor[(1, 300, 300, 512), float32]
  %132 = transpose(%131, framework_op_name="vgg16_bn_6/Sequential_10/BatchNorm2d_12/aten_batch_norm/transpose_1", output_tensors_name=["vgg16_bn_6/Sequential_10/BatchNorm2d_12/aten_batch_norm/transpose_1:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_10/BatchNorm2d_12/aten_batch_norm/transpose_1", axes=[0, 3, 1, 2]) // ty=Tensor[(1, 512, 300, 300), float32]
  %133 = nn.relu(%132, framework_op_name="vgg16_bn_6/Sequential_10/BatchNorm2d_12/aten_relu/Relu", output_tensors_name=["vgg16_bn_6/Sequential_10/BatchNorm2d_12/aten_relu/Relu:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_10/BatchNorm2d_12/aten_relu/Relu", axis=0) // ty=Tensor[(1, 512, 300, 300), float32]
  %134 = transpose(%133, framework_op_name="vgg16_bn_6/Sequential_10/MaxPool2d_14/aten_max_pool2d/transpose", output_tensors_name=["vgg16_bn_6/Sequential_10/MaxPool2d_14/aten_max_pool2d/transpose:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_10/MaxPool2d_14/aten_max_pool2d/transpose", axes=[0, 2, 3, 1]) // ty=Tensor[(1, 300, 300, 512), float32]
  %135 = nn.max_pool2d(%134, framework_op_name="vgg16_bn_6/Sequential_10/MaxPool2d_14/aten_max_pool2d/MaxPool2d", output_tensors_name=["vgg16_bn_6/Sequential_10/MaxPool2d_14/aten_max_pool2d/MaxPool2d:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_10/MaxPool2d_14/aten_max_pool2d/MaxPool2d", pool_size=[2, 2], pool_type="", strides=[2, 2], layout="NHWC") // ty=Tensor[(1, 150, 150, 512), float32]
  %136 = transpose(%135, framework_op_name="vgg16_bn_6/Sequential_10/MaxPool2d_14/aten_max_pool2d/transpose_1", output_tensors_name=["vgg16_bn_6/Sequential_10/MaxPool2d_14/aten_max_pool2d/transpose_1:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_10/MaxPool2d_14/aten_max_pool2d/transpose_1", axes=[0, 3, 1, 2]) // ty=Tensor[(1, 512, 150, 150), float32]
  %137 = transpose(%136, framework_op_name="vgg16_bn_6/Sequential_10/Conv2d_15/aten__convolution/transpose", output_tensors_name=["vgg16_bn_6/Sequential_10/Conv2d_15/aten__convolution/transpose:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_10/Conv2d_15/aten__convolution/transpose", axes=[0, 2, 3, 1]) // ty=Tensor[(1, 150, 150, 512), float32]
  %138 = nn.pad(%137, framework_op_name="vgg16_bn_6/Sequential_10/Conv2d_15/aten__convolution/Pad", output_tensors_name=["vgg16_bn_6/Sequential_10/Conv2d_15/aten__convolution/Pad:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_10/Conv2d_15/aten__convolution/Pad", pad_width=[[0, 0], [1, 1], [1, 1], [0, 0]]) // ty=Tensor[(1, 152, 152, 512), float32]
  %139 = nn.conv2d(%138, meta[relay.Constant][60] // ty=Tensor[(3, 3, 512, 512), float32], framework_op_name="vgg16_bn_6/Sequential_10/Conv2d_15/aten__convolution/Conv2D", output_tensors_name=["vgg16_bn_6/Sequential_10/Conv2d_15/aten__convolution/Conv2D:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_10/Conv2d_15/aten__convolution/Conv2D", channels=512, kernel_size=[3, 3], data_layout="NHWC", kernel_layout="HWIO") // ty=Tensor[(1, 150, 150, 512), float32]
  %140 = add(%139, meta[relay.Constant][61] // ty=Tensor[(512,), float32], framework_op_name="vgg16_bn_6/Sequential_10/Conv2d_15/aten__convolution/BiasAdd", output_tensors_name=["vgg16_bn_6/Sequential_10/Conv2d_15/aten__convolution/BiasAdd:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_10/Conv2d_15/aten__convolution/BiasAdd", axis=0) // ty=Tensor[(1, 150, 150, 512), float32]
  %141 = transpose(%140, framework_op_name="vgg16_bn_6/Sequential_10/Conv2d_15/aten__convolution/transpose_2", output_tensors_name=["vgg16_bn_6/Sequential_10/Conv2d_15/aten__convolution/transpose_2:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_10/Conv2d_15/aten__convolution/transpose_2", axes=[0, 3, 1, 2]) // ty=Tensor[(1, 512, 150, 150), float32]
  %142 = transpose(%141, framework_op_name="vgg16_bn_6/Sequential_10/BatchNorm2d_16/aten_batch_norm/transpose", output_tensors_name=["vgg16_bn_6/Sequential_10/BatchNorm2d_16/aten_batch_norm/transpose:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_10/BatchNorm2d_16/aten_batch_norm/transpose", axes=[0, 2, 3, 1]) // ty=Tensor[(1, 150, 150, 512), float32]
  %143 = subtract(%142, meta[relay.Constant][62] // ty=Tensor[(512,), float32], framework_op_name="vgg16_bn_6/Sequential_10/BatchNorm2d_16/aten_batch_norm/sub", output_tensors_name=["vgg16_bn_6/Sequential_10/BatchNorm2d_16/aten_batch_norm/sub:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_10/BatchNorm2d_16/aten_batch_norm/sub", axis=0) // ty=Tensor[(1, 150, 150, 512), float32]
  %144 = multiply(%143, meta[relay.Constant][63] // ty=Tensor[(512,), float32], framework_op_name="vgg16_bn_6/Sequential_10/BatchNorm2d_16/aten_batch_norm/truediv", output_tensors_name=["vgg16_bn_6/Sequential_10/BatchNorm2d_16/aten_batch_norm/truediv:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_10/BatchNorm2d_16/aten_batch_norm/truediv", axis=0) // ty=Tensor[(1, 150, 150, 512), float32]
  %145 = multiply(%144, meta[relay.Constant][64] // ty=Tensor[(512,), float32], framework_op_name="vgg16_bn_6/Sequential_10/BatchNorm2d_16/aten_batch_norm/mul", output_tensors_name=["vgg16_bn_6/Sequential_10/BatchNorm2d_16/aten_batch_norm/mul:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_10/BatchNorm2d_16/aten_batch_norm/mul", axis=0) // ty=Tensor[(1, 150, 150, 512), float32]
  %146 = add(%145, meta[relay.Constant][65] // ty=Tensor[(512,), float32], framework_op_name="vgg16_bn_6/Sequential_10/BatchNorm2d_16/aten_batch_norm/add_1", output_tensors_name=["vgg16_bn_6/Sequential_10/BatchNorm2d_16/aten_batch_norm/add_1:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_10/BatchNorm2d_16/aten_batch_norm/add_1", axis=0) // ty=Tensor[(1, 150, 150, 512), float32]
  %147 = transpose(%146, framework_op_name="vgg16_bn_6/Sequential_10/BatchNorm2d_16/aten_batch_norm/transpose_1", output_tensors_name=["vgg16_bn_6/Sequential_10/BatchNorm2d_16/aten_batch_norm/transpose_1:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_10/BatchNorm2d_16/aten_batch_norm/transpose_1", axes=[0, 3, 1, 2]) // ty=Tensor[(1, 512, 150, 150), float32]
  %148 = nn.relu(%147, framework_op_name="vgg16_bn_6/Sequential_10/BatchNorm2d_16/aten_relu/Relu", output_tensors_name=["vgg16_bn_6/Sequential_10/BatchNorm2d_16/aten_relu/Relu:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_10/BatchNorm2d_16/aten_relu/Relu", axis=0) // ty=Tensor[(1, 512, 150, 150), float32]
  %149 = transpose(%148, framework_op_name="vgg16_bn_6/Sequential_10/Conv2d_18/aten__convolution/transpose", output_tensors_name=["vgg16_bn_6/Sequential_10/Conv2d_18/aten__convolution/transpose:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_10/Conv2d_18/aten__convolution/transpose", axes=[0, 2, 3, 1]) // ty=Tensor[(1, 150, 150, 512), float32]
  %150 = nn.pad(%149, framework_op_name="vgg16_bn_6/Sequential_10/Conv2d_18/aten__convolution/Pad", output_tensors_name=["vgg16_bn_6/Sequential_10/Conv2d_18/aten__convolution/Pad:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_10/Conv2d_18/aten__convolution/Pad", pad_width=[[0, 0], [1, 1], [1, 1], [0, 0]]) // ty=Tensor[(1, 152, 152, 512), float32]
  %151 = nn.conv2d(%150, meta[relay.Constant][66] // ty=Tensor[(3, 3, 512, 512), float32], framework_op_name="vgg16_bn_6/Sequential_10/Conv2d_18/aten__convolution/Conv2D", output_tensors_name=["vgg16_bn_6/Sequential_10/Conv2d_18/aten__convolution/Conv2D:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_10/Conv2d_18/aten__convolution/Conv2D", channels=512, kernel_size=[3, 3], data_layout="NHWC", kernel_layout="HWIO") // ty=Tensor[(1, 150, 150, 512), float32]
  %152 = add(%151, meta[relay.Constant][67] // ty=Tensor[(512,), float32], framework_op_name="vgg16_bn_6/Sequential_10/Conv2d_18/aten__convolution/BiasAdd", output_tensors_name=["vgg16_bn_6/Sequential_10/Conv2d_18/aten__convolution/BiasAdd:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_10/Conv2d_18/aten__convolution/BiasAdd", axis=0) // ty=Tensor[(1, 150, 150, 512), float32]
  %153 = transpose(%152, framework_op_name="vgg16_bn_6/Sequential_10/Conv2d_18/aten__convolution/transpose_2", output_tensors_name=["vgg16_bn_6/Sequential_10/Conv2d_18/aten__convolution/transpose_2:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_10/Conv2d_18/aten__convolution/transpose_2", axes=[0, 3, 1, 2]) // ty=Tensor[(1, 512, 150, 150), float32]
  %154 = transpose(%153, framework_op_name="vgg16_bn_6/Sequential_10/BatchNorm2d_19/aten_batch_norm/transpose", output_tensors_name=["vgg16_bn_6/Sequential_10/BatchNorm2d_19/aten_batch_norm/transpose:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_10/BatchNorm2d_19/aten_batch_norm/transpose", axes=[0, 2, 3, 1]) // ty=Tensor[(1, 150, 150, 512), float32]
  %155 = subtract(%154, meta[relay.Constant][68] // ty=Tensor[(512,), float32], framework_op_name="vgg16_bn_6/Sequential_10/BatchNorm2d_19/aten_batch_norm/sub", output_tensors_name=["vgg16_bn_6/Sequential_10/BatchNorm2d_19/aten_batch_norm/sub:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_10/BatchNorm2d_19/aten_batch_norm/sub", axis=0) // ty=Tensor[(1, 150, 150, 512), float32]
  %156 = multiply(%155, meta[relay.Constant][69] // ty=Tensor[(512,), float32], framework_op_name="vgg16_bn_6/Sequential_10/BatchNorm2d_19/aten_batch_norm/truediv", output_tensors_name=["vgg16_bn_6/Sequential_10/BatchNorm2d_19/aten_batch_norm/truediv:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_10/BatchNorm2d_19/aten_batch_norm/truediv", axis=0) // ty=Tensor[(1, 150, 150, 512), float32]
  %157 = multiply(%156, meta[relay.Constant][70] // ty=Tensor[(512,), float32], framework_op_name="vgg16_bn_6/Sequential_10/BatchNorm2d_19/aten_batch_norm/mul", output_tensors_name=["vgg16_bn_6/Sequential_10/BatchNorm2d_19/aten_batch_norm/mul:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_10/BatchNorm2d_19/aten_batch_norm/mul", axis=0) // ty=Tensor[(1, 150, 150, 512), float32]
  %158 = add(%157, meta[relay.Constant][71] // ty=Tensor[(512,), float32], framework_op_name="vgg16_bn_6/Sequential_10/BatchNorm2d_19/aten_batch_norm/add_1", output_tensors_name=["vgg16_bn_6/Sequential_10/BatchNorm2d_19/aten_batch_norm/add_1:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_10/BatchNorm2d_19/aten_batch_norm/add_1", axis=0) // ty=Tensor[(1, 150, 150, 512), float32]
  %159 = transpose(%158, framework_op_name="vgg16_bn_6/Sequential_10/BatchNorm2d_19/aten_batch_norm/transpose_1", output_tensors_name=["vgg16_bn_6/Sequential_10/BatchNorm2d_19/aten_batch_norm/transpose_1:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_10/BatchNorm2d_19/aten_batch_norm/transpose_1", axes=[0, 3, 1, 2]) // ty=Tensor[(1, 512, 150, 150), float32]
  %160 = transpose(%159, framework_op_name="vgg16_bn_6/Sequential_12/MaxPool2d_3/aten_max_pool2d/transpose", output_tensors_name=["vgg16_bn_6/Sequential_12/MaxPool2d_3/aten_max_pool2d/transpose:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_12/MaxPool2d_3/aten_max_pool2d/transpose", axes=[0, 2, 3, 1]) // ty=Tensor[(1, 150, 150, 512), float32]
  %161 = nn.pad(%160, framework_op_name="vgg16_bn_6/Sequential_12/MaxPool2d_3/aten_max_pool2d/PadV2", output_tensors_name=["vgg16_bn_6/Sequential_12/MaxPool2d_3/aten_max_pool2d/PadV2:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_12/MaxPool2d_3/aten_max_pool2d/PadV2", pad_value=-65000, pad_width=[[0, 0], [1, 1], [1, 1], [0, 0]]) // ty=Tensor[(1, 152, 152, 512), float32]
  %162 = nn.max_pool2d(%161, framework_op_name="vgg16_bn_6/Sequential_12/MaxPool2d_3/aten_max_pool2d/MaxPool2d", output_tensors_name=["vgg16_bn_6/Sequential_12/MaxPool2d_3/aten_max_pool2d/MaxPool2d:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_12/MaxPool2d_3/aten_max_pool2d/MaxPool2d", pool_size=[3, 3], pool_type="", layout="NHWC") // ty=Tensor[(1, 150, 150, 512), float32]
  %163 = transpose(%162, framework_op_name="vgg16_bn_6/Sequential_12/MaxPool2d_3/aten_max_pool2d/transpose_1", output_tensors_name=["vgg16_bn_6/Sequential_12/MaxPool2d_3/aten_max_pool2d/transpose_1:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_12/MaxPool2d_3/aten_max_pool2d/transpose_1", axes=[0, 3, 1, 2]) // ty=Tensor[(1, 512, 150, 150), float32]
  %164 = transpose(%163, framework_op_name="vgg16_bn_6/Sequential_12/Conv2d_4/aten__convolution/transpose", output_tensors_name=["vgg16_bn_6/Sequential_12/Conv2d_4/aten__convolution/transpose:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_12/Conv2d_4/aten__convolution/transpose", axes=[0, 2, 3, 1]) // ty=Tensor[(1, 150, 150, 512), float32]
  %165 = nn.pad(%164, framework_op_name="vgg16_bn_6/Sequential_12/Conv2d_4/aten__convolution/Pad", output_tensors_name=["vgg16_bn_6/Sequential_12/Conv2d_4/aten__convolution/Pad:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_12/Conv2d_4/aten__convolution/Pad", pad_width=[[0, 0], [6, 6], [6, 6], [0, 0]]) // ty=Tensor[(1, 162, 162, 512), float32]
  %166 = nn.conv2d(%165, meta[relay.Constant][72] // ty=Tensor[(3, 3, 512, 1024), float32], framework_op_name="vgg16_bn_6/Sequential_12/Conv2d_4/aten__convolution/Conv2D", output_tensors_name=["vgg16_bn_6/Sequential_12/Conv2d_4/aten__convolution/Conv2D:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_12/Conv2d_4/aten__convolution/Conv2D", dilation=[6, 6], channels=1024, kernel_size=[3, 3], data_layout="NHWC", kernel_layout="HWIO") // ty=Tensor[(1, 150, 150, 1024), float32]
  %167 = add(%166, meta[relay.Constant][73] // ty=Tensor[(1024,), float32], framework_op_name="vgg16_bn_6/Sequential_12/Conv2d_4/aten__convolution/BiasAdd", output_tensors_name=["vgg16_bn_6/Sequential_12/Conv2d_4/aten__convolution/BiasAdd:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_12/Conv2d_4/aten__convolution/BiasAdd", axis=0) // ty=Tensor[(1, 150, 150, 1024), float32]
  %168 = transpose(%167, framework_op_name="vgg16_bn_6/Sequential_12/Conv2d_4/aten__convolution/transpose_2", output_tensors_name=["vgg16_bn_6/Sequential_12/Conv2d_4/aten__convolution/transpose_2:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_12/Conv2d_4/aten__convolution/transpose_2", axes=[0, 3, 1, 2]) // ty=Tensor[(1, 1024, 150, 150), float32]
  %169 = transpose(%168, framework_op_name="vgg16_bn_6/Sequential_12/Conv2d_5/aten__convolution/transpose", output_tensors_name=["vgg16_bn_6/Sequential_12/Conv2d_5/aten__convolution/transpose:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_12/Conv2d_5/aten__convolution/transpose", axes=[0, 2, 3, 1]) // ty=Tensor[(1, 150, 150, 1024), float32]
  %170 = nn.conv2d(%169, meta[relay.Constant][74] // ty=Tensor[(1, 1, 1024, 1024), float32], framework_op_name="vgg16_bn_6/Sequential_12/Conv2d_5/aten__convolution/Conv2D", output_tensors_name=["vgg16_bn_6/Sequential_12/Conv2d_5/aten__convolution/Conv2D:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_12/Conv2d_5/aten__convolution/Conv2D", channels=1024, kernel_size=[1, 1], data_layout="NHWC", kernel_layout="HWIO") // ty=Tensor[(1, 150, 150, 1024), float32]
  %171 = add(%170, meta[relay.Constant][75] // ty=Tensor[(1024,), float32], framework_op_name="vgg16_bn_6/Sequential_12/Conv2d_5/aten__convolution/BiasAdd", output_tensors_name=["vgg16_bn_6/Sequential_12/Conv2d_5/aten__convolution/BiasAdd:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_12/Conv2d_5/aten__convolution/BiasAdd", axis=0) // ty=Tensor[(1, 150, 150, 1024), float32]
  %172 = transpose(%171, framework_op_name="vgg16_bn_6/Sequential_12/Conv2d_5/aten__convolution/transpose_2", output_tensors_name=["vgg16_bn_6/Sequential_12/Conv2d_5/aten__convolution/transpose_2:0"], input_tensors_name=[], framework_op_debug_info="vgg16_bn_6/Sequential_12/Conv2d_5/aten__convolution/transpose_2", axes=[0, 3, 1, 2]) // ty=Tensor[(1, 1024, 150, 150), float32]
  %173 = copy(%172, framework_op_name="copy1", output_tensors_name=["copy1:0"], input_tensors_name=[], framework_op_debug_info="aten_cat/concat", axis=0) // ty=Tensor[(1, 1024, 150, 150), float32]
  %174 = copy(%159, framework_op_name="copy2", output_tensors_name=["copy2:0"], input_tensors_name=[], framework_op_debug_info="aten_cat/concat", axis=0) // ty=Tensor[(1, 512, 150, 150), float32]
  %175 = (%173, %174)
  %176 = concatenate(%175, framework_op_name="aten_cat/concat", output_tensors_name=["aten_cat/concat:0"], input_tensors_name=[], framework_op_debug_info="aten_cat/concat", axis=1) // ty=Tensor[(1, 1536, 150, 150), float32]
  %177 = transpose(%176, framework_op_name="double_conv_11/Sequential_1/Conv2d_6/aten__convolution/transpose", output_tensors_name=["double_conv_11/Sequential_1/Conv2d_6/aten__convolution/transpose:0"], input_tensors_name=[], framework_op_debug_info="double_conv_11/Sequential_1/Conv2d_6/aten__convolution/transpose", axes=[0, 2, 3, 1]) // ty=Tensor[(1, 150, 150, 1536), float32]
  %178 = nn.conv2d(%177, meta[relay.Constant][76] // ty=Tensor[(1, 1, 1536, 512), float32], framework_op_name="double_conv_11/Sequential_1/Conv2d_6/aten__convolution/Conv2D", output_tensors_name=["double_conv_11/Sequential_1/Conv2d_6/aten__convolution/Conv2D:0"], input_tensors_name=[], framework_op_debug_info="double_conv_11/Sequential_1/Conv2d_6/aten__convolution/Conv2D", channels=512, kernel_size=[1, 1], data_layout="NHWC", kernel_layout="HWIO") // ty=Tensor[(1, 150, 150, 512), float32]
  %179 = add(%178, meta[relay.Constant][77] // ty=Tensor[(512,), float32], framework_op_name="double_conv_11/Sequential_1/Conv2d_6/aten__convolution/BiasAdd", output_tensors_name=["double_conv_11/Sequential_1/Conv2d_6/aten__convolution/BiasAdd:0"], input_tensors_name=[], framework_op_debug_info="double_conv_11/Sequential_1/Conv2d_6/aten__convolution/BiasAdd", axis=0) // ty=Tensor[(1, 150, 150, 512), float32]
  %180 = transpose(%179, framework_op_name="double_conv_11/Sequential_1/Conv2d_6/aten__convolution/transpose_2", output_tensors_name=["double_conv_11/Sequential_1/Conv2d_6/aten__convolution/transpose_2:0"], input_tensors_name=[], framework_op_debug_info="double_conv_11/Sequential_1/Conv2d_6/aten__convolution/transpose_2", axes=[0, 3, 1, 2]) // ty=Tensor[(1, 512, 150, 150), float32]
  %181 = transpose(%180, framework_op_name="double_conv_11/Sequential_1/BatchNorm2d_7/aten_batch_norm/transpose", output_tensors_name=["double_conv_11/Sequential_1/BatchNorm2d_7/aten_batch_norm/transpose:0"], input_tensors_name=[], framework_op_debug_info="double_conv_11/Sequential_1/BatchNorm2d_7/aten_batch_norm/transpose", axes=[0, 2, 3, 1]) // ty=Tensor[(1, 150, 150, 512), float32]
  %182 = subtract(%181, meta[relay.Constant][78] // ty=Tensor[(512,), float32], framework_op_name="double_conv_11/Sequential_1/BatchNorm2d_7/aten_batch_norm/sub", output_tensors_name=["double_conv_11/Sequential_1/BatchNorm2d_7/aten_batch_norm/sub:0"], input_tensors_name=[], framework_op_debug_info="double_conv_11/Sequential_1/BatchNorm2d_7/aten_batch_norm/sub", axis=0) // ty=Tensor[(1, 150, 150, 512), float32]
  %183 = multiply(%182, meta[relay.Constant][79] // ty=Tensor[(512,), float32], framework_op_name="double_conv_11/Sequential_1/BatchNorm2d_7/aten_batch_norm/truediv", output_tensors_name=["double_conv_11/Sequential_1/BatchNorm2d_7/aten_batch_norm/truediv:0"], input_tensors_name=[], framework_op_debug_info="double_conv_11/Sequential_1/BatchNorm2d_7/aten_batch_norm/truediv", axis=0) // ty=Tensor[(1, 150, 150, 512), float32]
  %184 = multiply(%183, meta[relay.Constant][80] // ty=Tensor[(512,), float32], framework_op_name="double_conv_11/Sequential_1/BatchNorm2d_7/aten_batch_norm/mul", output_tensors_name=["double_conv_11/Sequential_1/BatchNorm2d_7/aten_batch_norm/mul:0"], input_tensors_name=[], framework_op_debug_info="double_conv_11/Sequential_1/BatchNorm2d_7/aten_batch_norm/mul", axis=0) // ty=Tensor[(1, 150, 150, 512), float32]
  %185 = add(%184, meta[relay.Constant][81] // ty=Tensor[(512,), float32], framework_op_name="double_conv_11/Sequential_1/BatchNorm2d_7/aten_batch_norm/add_1", output_tensors_name=["double_conv_11/Sequential_1/BatchNorm2d_7/aten_batch_norm/add_1:0"], input_tensors_name=[], framework_op_debug_info="double_conv_11/Sequential_1/BatchNorm2d_7/aten_batch_norm/add_1", axis=0) // ty=Tensor[(1, 150, 150, 512), float32]
  %186 = transpose(%185, framework_op_name="double_conv_11/Sequential_1/BatchNorm2d_7/aten_batch_norm/transpose_1", output_tensors_name=["double_conv_11/Sequential_1/BatchNorm2d_7/aten_batch_norm/transpose_1:0"], input_tensors_name=[], framework_op_debug_info="double_conv_11/Sequential_1/BatchNorm2d_7/aten_batch_norm/transpose_1", axes=[0, 3, 1, 2]) // ty=Tensor[(1, 512, 150, 150), float32]
  %187 = nn.relu(%186, framework_op_name="double_conv_11/Sequential_1/BatchNorm2d_7/aten_relu/Relu", output_tensors_name=["double_conv_11/Sequential_1/BatchNorm2d_7/aten_relu/Relu:0"], input_tensors_name=[], framework_op_debug_info="double_conv_11/Sequential_1/BatchNorm2d_7/aten_relu/Relu", axis=0) // ty=Tensor[(1, 512, 150, 150), float32]
  %188 = transpose(%187, framework_op_name="double_conv_11/Sequential_1/Conv2d_9/aten__convolution/transpose", output_tensors_name=["double_conv_11/Sequential_1/Conv2d_9/aten__convolution/transpose:0"], input_tensors_name=[], framework_op_debug_info="double_conv_11/Sequential_1/Conv2d_9/aten__convolution/transpose", axes=[0, 2, 3, 1]) // ty=Tensor[(1, 150, 150, 512), float32]
  %189 = nn.pad(%188, framework_op_name="double_conv_11/Sequential_1/Conv2d_9/aten__convolution/Pad", output_tensors_name=["double_conv_11/Sequential_1/Conv2d_9/aten__convolution/Pad:0"], input_tensors_name=[], framework_op_debug_info="double_conv_11/Sequential_1/Conv2d_9/aten__convolution/Pad", pad_width=[[0, 0], [1, 1], [1, 1], [0, 0]]) // ty=Tensor[(1, 152, 152, 512), float32]
  %190 = nn.conv2d(%189, meta[relay.Constant][82] // ty=Tensor[(3, 3, 512, 256), float32], framework_op_name="double_conv_11/Sequential_1/Conv2d_9/aten__convolution/Conv2D", output_tensors_name=["double_conv_11/Sequential_1/Conv2d_9/aten__convolution/Conv2D:0"], input_tensors_name=[], framework_op_debug_info="double_conv_11/Sequential_1/Conv2d_9/aten__convolution/Conv2D", channels=256, kernel_size=[3, 3], data_layout="NHWC", kernel_layout="HWIO") // ty=Tensor[(1, 150, 150, 256), float32]
  %191 = add(%190, meta[relay.Constant][83] // ty=Tensor[(256,), float32], framework_op_name="double_conv_11/Sequential_1/Conv2d_9/aten__convolution/BiasAdd", output_tensors_name=["double_conv_11/Sequential_1/Conv2d_9/aten__convolution/BiasAdd:0"], input_tensors_name=[], framework_op_debug_info="double_conv_11/Sequential_1/Conv2d_9/aten__convolution/BiasAdd", axis=0) // ty=Tensor[(1, 150, 150, 256), float32]
  %192 = transpose(%191, framework_op_name="double_conv_11/Sequential_1/Conv2d_9/aten__convolution/transpose_2", output_tensors_name=["double_conv_11/Sequential_1/Conv2d_9/aten__convolution/transpose_2:0"], input_tensors_name=[], framework_op_debug_info="double_conv_11/Sequential_1/Conv2d_9/aten__convolution/transpose_2", axes=[0, 3, 1, 2]) // ty=Tensor[(1, 256, 150, 150), float32]
  %193 = transpose(%192, framework_op_name="double_conv_11/Sequential_1/BatchNorm2d_10/aten_batch_norm/transpose", output_tensors_name=["double_conv_11/Sequential_1/BatchNorm2d_10/aten_batch_norm/transpose:0"], input_tensors_name=[], framework_op_debug_info="double_conv_11/Sequential_1/BatchNorm2d_10/aten_batch_norm/transpose", axes=[0, 2, 3, 1]) // ty=Tensor[(1, 150, 150, 256), float32]
  %194 = subtract(%193, meta[relay.Constant][84] // ty=Tensor[(256,), float32], framework_op_name="double_conv_11/Sequential_1/BatchNorm2d_10/aten_batch_norm/sub", output_tensors_name=["double_conv_11/Sequential_1/BatchNorm2d_10/aten_batch_norm/sub:0"], input_tensors_name=[], framework_op_debug_info="double_conv_11/Sequential_1/BatchNorm2d_10/aten_batch_norm/sub", axis=0) // ty=Tensor[(1, 150, 150, 256), float32]
  %195 = multiply(%194, meta[relay.Constant][85] // ty=Tensor[(256,), float32], framework_op_name="double_conv_11/Sequential_1/BatchNorm2d_10/aten_batch_norm/truediv", output_tensors_name=["double_conv_11/Sequential_1/BatchNorm2d_10/aten_batch_norm/truediv:0"], input_tensors_name=[], framework_op_debug_info="double_conv_11/Sequential_1/BatchNorm2d_10/aten_batch_norm/truediv", axis=0) // ty=Tensor[(1, 150, 150, 256), float32]
  %196 = multiply(%195, meta[relay.Constant][86] // ty=Tensor[(256,), float32], framework_op_name="double_conv_11/Sequential_1/BatchNorm2d_10/aten_batch_norm/mul", output_tensors_name=["double_conv_11/Sequential_1/BatchNorm2d_10/aten_batch_norm/mul:0"], input_tensors_name=[], framework_op_debug_info="double_conv_11/Sequential_1/BatchNorm2d_10/aten_batch_norm/mul", axis=0) // ty=Tensor[(1, 150, 150, 256), float32]
  %197 = add(%196, meta[relay.Constant][87] // ty=Tensor[(256,), float32], framework_op_name="double_conv_11/Sequential_1/BatchNorm2d_10/aten_batch_norm/add_1", output_tensors_name=["double_conv_11/Sequential_1/BatchNorm2d_10/aten_batch_norm/add_1:0"], input_tensors_name=[], framework_op_debug_info="double_conv_11/Sequential_1/BatchNorm2d_10/aten_batch_norm/add_1", axis=0) // ty=Tensor[(1, 150, 150, 256), float32]
  %198 = transpose(%197, framework_op_name="double_conv_11/Sequential_1/BatchNorm2d_10/aten_batch_norm/transpose_1", output_tensors_name=["double_conv_11/Sequential_1/BatchNorm2d_10/aten_batch_norm/transpose_1:0"], input_tensors_name=[], framework_op_debug_info="double_conv_11/Sequential_1/BatchNorm2d_10/aten_batch_norm/transpose_1", axes=[0, 3, 1, 2]) // ty=Tensor[(1, 256, 150, 150), float32]
  %199 = nn.relu(%198, framework_op_name="double_conv_11/Sequential_1/BatchNorm2d_10/aten_relu/Relu", output_tensors_name=["double_conv_11/Sequential_1/BatchNorm2d_10/aten_relu/Relu:0"], input_tensors_name=[], framework_op_debug_info="double_conv_11/Sequential_1/BatchNorm2d_10/aten_relu/Relu", axis=0) // ty=Tensor[(1, 256, 150, 150), float32]
  %200 = transpose(%199, framework_op_name="aten_upsample_bilinear2d/transpose", output_tensors_name=["aten_upsample_bilinear2d/transpose:0"], input_tensors_name=[], framework_op_debug_info="aten_upsample_bilinear2d/transpose", axes=[0, 2, 3, 1]) // ty=Tensor[(1, 150, 150, 256), float32]
  %201 = transpose(%200, framework_op_name="transpose0", output_tensors_name=["transpose0:0"], input_tensors_name=[], framework_op_debug_info="aten_upsample_bilinear2d/conv2d_transpose", axes=[0, 3, 1, 2]) // ty=Tensor[(1, 256, 150, 150), float32]
  %202 = nn.conv2d_transpose(%201, meta[relay.Constant][88] // ty=Tensor[(256, 256, 4, 4), float32], framework_op_name="nn.conv2d_transpose0", output_tensors_name=["nn.conv2d_transpose0:0"], input_tensors_name=[], framework_op_debug_info="aten_upsample_bilinear2d/conv2d_transpose", channels=256, kernel_size=[4, 4], strides=[2, 2], padding=[1, 1, 1, 1]) // ty=Tensor[(1, 256, 300, 300), float32]
  %203 = transpose(%202, framework_op_name="aten_upsample_bilinear2d/conv2d_transpose", output_tensors_name=["aten_upsample_bilinear2d/conv2d_transpose:0"], input_tensors_name=[], framework_op_debug_info="aten_upsample_bilinear2d/conv2d_transpose", axes=[0, 2, 3, 1]) // ty=Tensor[(1, 300, 300, 256), float32]
  %204 = transpose(%203, framework_op_name="aten_upsample_bilinear2d/transpose_1", output_tensors_name=["aten_upsample_bilinear2d/transpose_1:0"], input_tensors_name=[], framework_op_debug_info="aten_upsample_bilinear2d/transpose_1", axes=[0, 3, 1, 2]) // ty=Tensor[(1, 256, 300, 300), float32]
  %205 = multiply(%204, meta[relay.Constant][89] // ty=Tensor[(300, 300), float32], framework_op_name="aten_upsample_bilinear2d/Mul", output_tensors_name=["aten_upsample_bilinear2d/Mul:0"], input_tensors_name=[], framework_op_debug_info="aten_upsample_bilinear2d/Mul", axis=0) // ty=Tensor[(1, 256, 300, 300), float32]
  %206 = copy(%205, framework_op_name="copy3", output_tensors_name=["copy3:0"], input_tensors_name=[], framework_op_debug_info="aten_cat_1/concat", axis=0) // ty=Tensor[(1, 256, 300, 300), float32]
  %207 = copy(%121, framework_op_name="copy4", output_tensors_name=["copy4:0"], input_tensors_name=[], framework_op_debug_info="aten_cat_1/concat", axis=0) // ty=Tensor[(1, 512, 300, 300), float32]
  %208 = (%206, %207)
  %209 = concatenate(%208, framework_op_name="aten_cat_1/concat", output_tensors_name=["aten_cat_1/concat:0"], input_tensors_name=[], framework_op_debug_info="aten_cat_1/concat", axis=1) // ty=Tensor[(1, 768, 300, 300), float32]
  %210 = transpose(%209, framework_op_name="double_conv_27/Sequential_1/Conv2d_6/aten__convolution/transpose", output_tensors_name=["double_conv_27/Sequential_1/Conv2d_6/aten__convolution/transpose:0"], input_tensors_name=[], framework_op_debug_info="double_conv_27/Sequential_1/Conv2d_6/aten__convolution/transpose", axes=[0, 2, 3, 1]) // ty=Tensor[(1, 300, 300, 768), float32]
  %211 = nn.conv2d(%210, meta[relay.Constant][90] // ty=Tensor[(1, 1, 768, 256), float32], framework_op_name="double_conv_27/Sequential_1/Conv2d_6/aten__convolution/Conv2D", output_tensors_name=["double_conv_27/Sequential_1/Conv2d_6/aten__convolution/Conv2D:0"], input_tensors_name=[], framework_op_debug_info="double_conv_27/Sequential_1/Conv2d_6/aten__convolution/Conv2D", channels=256, kernel_size=[1, 1], data_layout="NHWC", kernel_layout="HWIO") // ty=Tensor[(1, 300, 300, 256), float32]
  %212 = add(%211, meta[relay.Constant][91] // ty=Tensor[(256,), float32], framework_op_name="double_conv_27/Sequential_1/Conv2d_6/aten__convolution/BiasAdd", output_tensors_name=["double_conv_27/Sequential_1/Conv2d_6/aten__convolution/BiasAdd:0"], input_tensors_name=[], framework_op_debug_info="double_conv_27/Sequential_1/Conv2d_6/aten__convolution/BiasAdd", axis=0) // ty=Tensor[(1, 300, 300, 256), float32]
  %213 = transpose(%212, framework_op_name="double_conv_27/Sequential_1/Conv2d_6/aten__convolution/transpose_2", output_tensors_name=["double_conv_27/Sequential_1/Conv2d_6/aten__convolution/transpose_2:0"], input_tensors_name=[], framework_op_debug_info="double_conv_27/Sequential_1/Conv2d_6/aten__convolution/transpose_2", axes=[0, 3, 1, 2]) // ty=Tensor[(1, 256, 300, 300), float32]
  %214 = transpose(%213, framework_op_name="double_conv_27/Sequential_1/BatchNorm2d_7/aten_batch_norm/transpose", output_tensors_name=["double_conv_27/Sequential_1/BatchNorm2d_7/aten_batch_norm/transpose:0"], input_tensors_name=[], framework_op_debug_info="double_conv_27/Sequential_1/BatchNorm2d_7/aten_batch_norm/transpose", axes=[0, 2, 3, 1]) // ty=Tensor[(1, 300, 300, 256), float32]
  %215 = subtract(%214, meta[relay.Constant][92] // ty=Tensor[(256,), float32], framework_op_name="double_conv_27/Sequential_1/BatchNorm2d_7/aten_batch_norm/sub", output_tensors_name=["double_conv_27/Sequential_1/BatchNorm2d_7/aten_batch_norm/sub:0"], input_tensors_name=[], framework_op_debug_info="double_conv_27/Sequential_1/BatchNorm2d_7/aten_batch_norm/sub", axis=0) // ty=Tensor[(1, 300, 300, 256), float32]
  %216 = multiply(%215, meta[relay.Constant][93] // ty=Tensor[(256,), float32], framework_op_name="double_conv_27/Sequential_1/BatchNorm2d_7/aten_batch_norm/truediv", output_tensors_name=["double_conv_27/Sequential_1/BatchNorm2d_7/aten_batch_norm/truediv:0"], input_tensors_name=[], framework_op_debug_info="double_conv_27/Sequential_1/BatchNorm2d_7/aten_batch_norm/truediv", axis=0) // ty=Tensor[(1, 300, 300, 256), float32]
  %217 = multiply(%216, meta[relay.Constant][94] // ty=Tensor[(256,), float32], framework_op_name="double_conv_27/Sequential_1/BatchNorm2d_7/aten_batch_norm/mul", output_tensors_name=["double_conv_27/Sequential_1/BatchNorm2d_7/aten_batch_norm/mul:0"], input_tensors_name=[], framework_op_debug_info="double_conv_27/Sequential_1/BatchNorm2d_7/aten_batch_norm/mul", axis=0) // ty=Tensor[(1, 300, 300, 256), float32]
  %218 = add(%217, meta[relay.Constant][95] // ty=Tensor[(256,), float32], framework_op_name="double_conv_27/Sequential_1/BatchNorm2d_7/aten_batch_norm/add_1", output_tensors_name=["double_conv_27/Sequential_1/BatchNorm2d_7/aten_batch_norm/add_1:0"], input_tensors_name=[], framework_op_debug_info="double_conv_27/Sequential_1/BatchNorm2d_7/aten_batch_norm/add_1", axis=0) // ty=Tensor[(1, 300, 300, 256), float32]
  %219 = transpose(%218, framework_op_name="double_conv_27/Sequential_1/BatchNorm2d_7/aten_batch_norm/transpose_1", output_tensors_name=["double_conv_27/Sequential_1/BatchNorm2d_7/aten_batch_norm/transpose_1:0"], input_tensors_name=[], framework_op_debug_info="double_conv_27/Sequential_1/BatchNorm2d_7/aten_batch_norm/transpose_1", axes=[0, 3, 1, 2]) // ty=Tensor[(1, 256, 300, 300), float32]
  %220 = nn.relu(%219, framework_op_name="double_conv_27/Sequential_1/BatchNorm2d_7/aten_relu/Relu", output_tensors_name=["double_conv_27/Sequential_1/BatchNorm2d_7/aten_relu/Relu:0"], input_tensors_name=[], framework_op_debug_info="double_conv_27/Sequential_1/BatchNorm2d_7/aten_relu/Relu", axis=0) // ty=Tensor[(1, 256, 300, 300), float32]
  %221 = transpose(%220, framework_op_name="double_conv_27/Sequential_1/Conv2d_9/aten__convolution/transpose", output_tensors_name=["double_conv_27/Sequential_1/Conv2d_9/aten__convolution/transpose:0"], input_tensors_name=[], framework_op_debug_info="double_conv_27/Sequential_1/Conv2d_9/aten__convolution/transpose", axes=[0, 2, 3, 1]) // ty=Tensor[(1, 300, 300, 256), float32]
  %222 = nn.pad(%221, framework_op_name="double_conv_27/Sequential_1/Conv2d_9/aten__convolution/Pad", output_tensors_name=["double_conv_27/Sequential_1/Conv2d_9/aten__convolution/Pad:0"], input_tensors_name=[], framework_op_debug_info="double_conv_27/Sequential_1/Conv2d_9/aten__convolution/Pad", pad_width=[[0, 0], [1, 1], [1, 1], [0, 0]]) // ty=Tensor[(1, 302, 302, 256), float32]
  %223 = nn.conv2d(%222, meta[relay.Constant][96] // ty=Tensor[(3, 3, 256, 128), float32], framework_op_name="double_conv_27/Sequential_1/Conv2d_9/aten__convolution/Conv2D", output_tensors_name=["double_conv_27/Sequential_1/Conv2d_9/aten__convolution/Conv2D:0"], input_tensors_name=[], framework_op_debug_info="double_conv_27/Sequential_1/Conv2d_9/aten__convolution/Conv2D", channels=128, kernel_size=[3, 3], data_layout="NHWC", kernel_layout="HWIO") // ty=Tensor[(1, 300, 300, 128), float32]
  %224 = add(%223, meta[relay.Constant][97] // ty=Tensor[(128,), float32], framework_op_name="double_conv_27/Sequential_1/Conv2d_9/aten__convolution/BiasAdd", output_tensors_name=["double_conv_27/Sequential_1/Conv2d_9/aten__convolution/BiasAdd:0"], input_tensors_name=[], framework_op_debug_info="double_conv_27/Sequential_1/Conv2d_9/aten__convolution/BiasAdd", axis=0) // ty=Tensor[(1, 300, 300, 128), float32]
  %225 = transpose(%224, framework_op_name="double_conv_27/Sequential_1/Conv2d_9/aten__convolution/transpose_2", output_tensors_name=["double_conv_27/Sequential_1/Conv2d_9/aten__convolution/transpose_2:0"], input_tensors_name=[], framework_op_debug_info="double_conv_27/Sequential_1/Conv2d_9/aten__convolution/transpose_2", axes=[0, 3, 1, 2]) // ty=Tensor[(1, 128, 300, 300), float32]
  %226 = transpose(%225, framework_op_name="double_conv_27/Sequential_1/BatchNorm2d_10/aten_batch_norm/transpose", output_tensors_name=["double_conv_27/Sequential_1/BatchNorm2d_10/aten_batch_norm/transpose:0"], input_tensors_name=[], framework_op_debug_info="double_conv_27/Sequential_1/BatchNorm2d_10/aten_batch_norm/transpose", axes=[0, 2, 3, 1]) // ty=Tensor[(1, 300, 300, 128), float32]
  %227 = subtract(%226, meta[relay.Constant][98] // ty=Tensor[(128,), float32], framework_op_name="double_conv_27/Sequential_1/BatchNorm2d_10/aten_batch_norm/sub", output_tensors_name=["double_conv_27/Sequential_1/BatchNorm2d_10/aten_batch_norm/sub:0"], input_tensors_name=[], framework_op_debug_info="double_conv_27/Sequential_1/BatchNorm2d_10/aten_batch_norm/sub", axis=0) // ty=Tensor[(1, 300, 300, 128), float32]
  %228 = multiply(%227, meta[relay.Constant][99] // ty=Tensor[(128,), float32], framework_op_name="double_conv_27/Sequential_1/BatchNorm2d_10/aten_batch_norm/truediv", output_tensors_name=["double_conv_27/Sequential_1/BatchNorm2d_10/aten_batch_norm/truediv:0"], input_tensors_name=[], framework_op_debug_info="double_conv_27/Sequential_1/BatchNorm2d_10/aten_batch_norm/truediv", axis=0) // ty=Tensor[(1, 300, 300, 128), float32]
  %229 = multiply(%228, meta[relay.Constant][100] // ty=Tensor[(128,), float32], framework_op_name="double_conv_27/Sequential_1/BatchNorm2d_10/aten_batch_norm/mul", output_tensors_name=["double_conv_27/Sequential_1/BatchNorm2d_10/aten_batch_norm/mul:0"], input_tensors_name=[], framework_op_debug_info="double_conv_27/Sequential_1/BatchNorm2d_10/aten_batch_norm/mul", axis=0) // ty=Tensor[(1, 300, 300, 128), float32]
  %230 = add(%229, meta[relay.Constant][101] // ty=Tensor[(128,), float32], framework_op_name="double_conv_27/Sequential_1/BatchNorm2d_10/aten_batch_norm/add_1", output_tensors_name=["double_conv_27/Sequential_1/BatchNorm2d_10/aten_batch_norm/add_1:0"], input_tensors_name=[], framework_op_debug_info="double_conv_27/Sequential_1/BatchNorm2d_10/aten_batch_norm/add_1", axis=0) // ty=Tensor[(1, 300, 300, 128), float32]
  %231 = transpose(%230, framework_op_name="double_conv_27/Sequential_1/BatchNorm2d_10/aten_batch_norm/transpose_1", output_tensors_name=["double_conv_27/Sequential_1/BatchNorm2d_10/aten_batch_norm/transpose_1:0"], input_tensors_name=[], framework_op_debug_info="double_conv_27/Sequential_1/BatchNorm2d_10/aten_batch_norm/transpose_1", axes=[0, 3, 1, 2]) // ty=Tensor[(1, 128, 300, 300), float32]
  %232 = nn.relu(%231, framework_op_name="double_conv_27/Sequential_1/BatchNorm2d_10/aten_relu/Relu", output_tensors_name=["double_conv_27/Sequential_1/BatchNorm2d_10/aten_relu/Relu:0"], input_tensors_name=[], framework_op_debug_info="double_conv_27/Sequential_1/BatchNorm2d_10/aten_relu/Relu", axis=0) // ty=Tensor[(1, 128, 300, 300), float32]
  %233 = transpose(%232, framework_op_name="aten_upsample_bilinear2d_1/transpose", output_tensors_name=["aten_upsample_bilinear2d_1/transpose:0"], input_tensors_name=[], framework_op_debug_info="aten_upsample_bilinear2d_1/transpose", axes=[0, 2, 3, 1]) // ty=Tensor[(1, 300, 300, 128), float32]
  %234 = transpose(%233, framework_op_name="transpose2", output_tensors_name=["transpose2:0"], input_tensors_name=[], framework_op_debug_info="aten_upsample_bilinear2d_1/conv2d_transpose", axes=[0, 3, 1, 2]) // ty=Tensor[(1, 128, 300, 300), float32]
  %235 = nn.conv2d_transpose(%234, meta[relay.Constant][102] // ty=Tensor[(128, 128, 4, 4), float32], framework_op_name="nn.conv2d_transpose1", output_tensors_name=["nn.conv2d_transpose1:0"], input_tensors_name=[], framework_op_debug_info="aten_upsample_bilinear2d_1/conv2d_transpose", channels=128, kernel_size=[4, 4], strides=[2, 2], padding=[1, 1, 1, 1]) // ty=Tensor[(1, 128, 600, 600), float32]
  %236 = transpose(%235, framework_op_name="aten_upsample_bilinear2d_1/conv2d_transpose", output_tensors_name=["aten_upsample_bilinear2d_1/conv2d_transpose:0"], input_tensors_name=[], framework_op_debug_info="aten_upsample_bilinear2d_1/conv2d_transpose", axes=[0, 2, 3, 1]) // ty=Tensor[(1, 600, 600, 128), float32]
  %237 = transpose(%236, framework_op_name="aten_upsample_bilinear2d_1/transpose_1", output_tensors_name=["aten_upsample_bilinear2d_1/transpose_1:0"], input_tensors_name=[], framework_op_debug_info="aten_upsample_bilinear2d_1/transpose_1", axes=[0, 3, 1, 2]) // ty=Tensor[(1, 128, 600, 600), float32]
  %238 = multiply(%237, meta[relay.Constant][103] // ty=Tensor[(600, 600), float32], framework_op_name="aten_upsample_bilinear2d_1/Mul", output_tensors_name=["aten_upsample_bilinear2d_1/Mul:0"], input_tensors_name=[], framework_op_debug_info="aten_upsample_bilinear2d_1/Mul", axis=0) // ty=Tensor[(1, 128, 600, 600), float32]
  %239 = copy(%238, framework_op_name="copy5", output_tensors_name=["copy5:0"], input_tensors_name=[], framework_op_debug_info="aten_cat_2/concat", axis=0) // ty=Tensor[(1, 128, 600, 600), float32]
  %240 = copy(%82, framework_op_name="copy6", output_tensors_name=["copy6:0"], input_tensors_name=[], framework_op_debug_info="aten_cat_2/concat", axis=0) // ty=Tensor[(1, 256, 600, 600), float32]
  %241 = (%239, %240)
  %242 = concatenate(%241, framework_op_name="aten_cat_2/concat", output_tensors_name=["aten_cat_2/concat:0"], input_tensors_name=[], framework_op_debug_info="aten_cat_2/concat", axis=1) // ty=Tensor[(1, 384, 600, 600), float32]
  %243 = transpose(%242, framework_op_name="double_conv_43/Sequential_1/Conv2d_6/aten__convolution/transpose", output_tensors_name=["double_conv_43/Sequential_1/Conv2d_6/aten__convolution/transpose:0"], input_tensors_name=[], framework_op_debug_info="double_conv_43/Sequential_1/Conv2d_6/aten__convolution/transpose", axes=[0, 2, 3, 1]) // ty=Tensor[(1, 600, 600, 384), float32]
  %244 = nn.conv2d(%243, meta[relay.Constant][104] // ty=Tensor[(1, 1, 384, 128), float32], framework_op_name="double_conv_43/Sequential_1/Conv2d_6/aten__convolution/Conv2D", output_tensors_name=["double_conv_43/Sequential_1/Conv2d_6/aten__convolution/Conv2D:0"], input_tensors_name=[], framework_op_debug_info="double_conv_43/Sequential_1/Conv2d_6/aten__convolution/Conv2D", channels=128, kernel_size=[1, 1], data_layout="NHWC", kernel_layout="HWIO") // ty=Tensor[(1, 600, 600, 128), float32]
  %245 = add(%244, meta[relay.Constant][105] // ty=Tensor[(128,), float32], framework_op_name="double_conv_43/Sequential_1/Conv2d_6/aten__convolution/BiasAdd", output_tensors_name=["double_conv_43/Sequential_1/Conv2d_6/aten__convolution/BiasAdd:0"], input_tensors_name=[], framework_op_debug_info="double_conv_43/Sequential_1/Conv2d_6/aten__convolution/BiasAdd", axis=0) // ty=Tensor[(1, 600, 600, 128), float32]
  %246 = transpose(%245, framework_op_name="double_conv_43/Sequential_1/Conv2d_6/aten__convolution/transpose_2", output_tensors_name=["double_conv_43/Sequential_1/Conv2d_6/aten__convolution/transpose_2:0"], input_tensors_name=[], framework_op_debug_info="double_conv_43/Sequential_1/Conv2d_6/aten__convolution/transpose_2", axes=[0, 3, 1, 2]) // ty=Tensor[(1, 128, 600, 600), float32]
  %247 = transpose(%246, framework_op_name="double_conv_43/Sequential_1/BatchNorm2d_7/aten_batch_norm/transpose", output_tensors_name=["double_conv_43/Sequential_1/BatchNorm2d_7/aten_batch_norm/transpose:0"], input_tensors_name=[], framework_op_debug_info="double_conv_43/Sequential_1/BatchNorm2d_7/aten_batch_norm/transpose", axes=[0, 2, 3, 1]) // ty=Tensor[(1, 600, 600, 128), float32]
  %248 = subtract(%247, meta[relay.Constant][106] // ty=Tensor[(128,), float32], framework_op_name="double_conv_43/Sequential_1/BatchNorm2d_7/aten_batch_norm/sub", output_tensors_name=["double_conv_43/Sequential_1/BatchNorm2d_7/aten_batch_norm/sub:0"], input_tensors_name=[], framework_op_debug_info="double_conv_43/Sequential_1/BatchNorm2d_7/aten_batch_norm/sub", axis=0) // ty=Tensor[(1, 600, 600, 128), float32]
  %249 = multiply(%248, meta[relay.Constant][107] // ty=Tensor[(128,), float32], framework_op_name="double_conv_43/Sequential_1/BatchNorm2d_7/aten_batch_norm/truediv", output_tensors_name=["double_conv_43/Sequential_1/BatchNorm2d_7/aten_batch_norm/truediv:0"], input_tensors_name=[], framework_op_debug_info="double_conv_43/Sequential_1/BatchNorm2d_7/aten_batch_norm/truediv", axis=0) // ty=Tensor[(1, 600, 600, 128), float32]
  %250 = multiply(%249, meta[relay.Constant][108] // ty=Tensor[(128,), float32], framework_op_name="double_conv_43/Sequential_1/BatchNorm2d_7/aten_batch_norm/mul", output_tensors_name=["double_conv_43/Sequential_1/BatchNorm2d_7/aten_batch_norm/mul:0"], input_tensors_name=[], framework_op_debug_info="double_conv_43/Sequential_1/BatchNorm2d_7/aten_batch_norm/mul", axis=0) // ty=Tensor[(1, 600, 600, 128), float32]
  %251 = add(%250, meta[relay.Constant][109] // ty=Tensor[(128,), float32], framework_op_name="double_conv_43/Sequential_1/BatchNorm2d_7/aten_batch_norm/add_1", output_tensors_name=["double_conv_43/Sequential_1/BatchNorm2d_7/aten_batch_norm/add_1:0"], input_tensors_name=[], framework_op_debug_info="double_conv_43/Sequential_1/BatchNorm2d_7/aten_batch_norm/add_1", axis=0) // ty=Tensor[(1, 600, 600, 128), float32]
  %252 = transpose(%251, framework_op_name="double_conv_43/Sequential_1/BatchNorm2d_7/aten_batch_norm/transpose_1", output_tensors_name=["double_conv_43/Sequential_1/BatchNorm2d_7/aten_batch_norm/transpose_1:0"], input_tensors_name=[], framework_op_debug_info="double_conv_43/Sequential_1/BatchNorm2d_7/aten_batch_norm/transpose_1", axes=[0, 3, 1, 2]) // ty=Tensor[(1, 128, 600, 600), float32]
  %253 = nn.relu(%252, framework_op_name="double_conv_43/Sequential_1/BatchNorm2d_7/aten_relu/Relu", output_tensors_name=["double_conv_43/Sequential_1/BatchNorm2d_7/aten_relu/Relu:0"], input_tensors_name=[], framework_op_debug_info="double_conv_43/Sequential_1/BatchNorm2d_7/aten_relu/Relu", axis=0) // ty=Tensor[(1, 128, 600, 600), float32]
  %254 = transpose(%253, framework_op_name="double_conv_43/Sequential_1/Conv2d_9/aten__convolution/transpose", output_tensors_name=["double_conv_43/Sequential_1/Conv2d_9/aten__convolution/transpose:0"], input_tensors_name=[], framework_op_debug_info="double_conv_43/Sequential_1/Conv2d_9/aten__convolution/transpose", axes=[0, 2, 3, 1]) // ty=Tensor[(1, 600, 600, 128), float32]
  %255 = nn.pad(%254, framework_op_name="double_conv_43/Sequential_1/Conv2d_9/aten__convolution/Pad", output_tensors_name=["double_conv_43/Sequential_1/Conv2d_9/aten__convolution/Pad:0"], input_tensors_name=[], framework_op_debug_info="double_conv_43/Sequential_1/Conv2d_9/aten__convolution/Pad", pad_width=[[0, 0], [1, 1], [1, 1], [0, 0]]) // ty=Tensor[(1, 602, 602, 128), float32]
  %256 = nn.conv2d(%255, meta[relay.Constant][110] // ty=Tensor[(3, 3, 128, 64), float32], framework_op_name="double_conv_43/Sequential_1/Conv2d_9/aten__convolution/Conv2D", output_tensors_name=["double_conv_43/Sequential_1/Conv2d_9/aten__convolution/Conv2D:0"], input_tensors_name=[], framework_op_debug_info="double_conv_43/Sequential_1/Conv2d_9/aten__convolution/Conv2D", channels=64, kernel_size=[3, 3], data_layout="NHWC", kernel_layout="HWIO") // ty=Tensor[(1, 600, 600, 64), float32]
  %257 = add(%256, meta[relay.Constant][111] // ty=Tensor[(64,), float32], framework_op_name="double_conv_43/Sequential_1/Conv2d_9/aten__convolution/BiasAdd", output_tensors_name=["double_conv_43/Sequential_1/Conv2d_9/aten__convolution/BiasAdd:0"], input_tensors_name=[], framework_op_debug_info="double_conv_43/Sequential_1/Conv2d_9/aten__convolution/BiasAdd", axis=0) // ty=Tensor[(1, 600, 600, 64), float32]
  %258 = transpose(%257, framework_op_name="double_conv_43/Sequential_1/Conv2d_9/aten__convolution/transpose_2", output_tensors_name=["double_conv_43/Sequential_1/Conv2d_9/aten__convolution/transpose_2:0"], input_tensors_name=[], framework_op_debug_info="double_conv_43/Sequential_1/Conv2d_9/aten__convolution/transpose_2", axes=[0, 3, 1, 2]) // ty=Tensor[(1, 64, 600, 600), float32]
  %259 = transpose(%258, framework_op_name="double_conv_43/Sequential_1/BatchNorm2d_10/aten_batch_norm/transpose", output_tensors_name=["double_conv_43/Sequential_1/BatchNorm2d_10/aten_batch_norm/transpose:0"], input_tensors_name=[], framework_op_debug_info="double_conv_43/Sequential_1/BatchNorm2d_10/aten_batch_norm/transpose", axes=[0, 2, 3, 1]) // ty=Tensor[(1, 600, 600, 64), float32]
  %260 = subtract(%259, meta[relay.Constant][112] // ty=Tensor[(64,), float32], framework_op_name="double_conv_43/Sequential_1/BatchNorm2d_10/aten_batch_norm/sub", output_tensors_name=["double_conv_43/Sequential_1/BatchNorm2d_10/aten_batch_norm/sub:0"], input_tensors_name=[], framework_op_debug_info="double_conv_43/Sequential_1/BatchNorm2d_10/aten_batch_norm/sub", axis=0) // ty=Tensor[(1, 600, 600, 64), float32]
  %261 = multiply(%260, meta[relay.Constant][113] // ty=Tensor[(64,), float32], framework_op_name="double_conv_43/Sequential_1/BatchNorm2d_10/aten_batch_norm/truediv", output_tensors_name=["double_conv_43/Sequential_1/BatchNorm2d_10/aten_batch_norm/truediv:0"], input_tensors_name=[], framework_op_debug_info="double_conv_43/Sequential_1/BatchNorm2d_10/aten_batch_norm/truediv", axis=0) // ty=Tensor[(1, 600, 600, 64), float32]
  %262 = multiply(%261, meta[relay.Constant][114] // ty=Tensor[(64,), float32], framework_op_name="double_conv_43/Sequential_1/BatchNorm2d_10/aten_batch_norm/mul", output_tensors_name=["double_conv_43/Sequential_1/BatchNorm2d_10/aten_batch_norm/mul:0"], input_tensors_name=[], framework_op_debug_info="double_conv_43/Sequential_1/BatchNorm2d_10/aten_batch_norm/mul", axis=0) // ty=Tensor[(1, 600, 600, 64), float32]
  %263 = add(%262, meta[relay.Constant][115] // ty=Tensor[(64,), float32], framework_op_name="double_conv_43/Sequential_1/BatchNorm2d_10/aten_batch_norm/add_1", output_tensors_name=["double_conv_43/Sequential_1/BatchNorm2d_10/aten_batch_norm/add_1:0"], input_tensors_name=[], framework_op_debug_info="double_conv_43/Sequential_1/BatchNorm2d_10/aten_batch_norm/add_1", axis=0) // ty=Tensor[(1, 600, 600, 64), float32]
  %264 = transpose(%263, framework_op_name="double_conv_43/Sequential_1/BatchNorm2d_10/aten_batch_norm/transpose_1", output_tensors_name=["double_conv_43/Sequential_1/BatchNorm2d_10/aten_batch_norm/transpose_1:0"], input_tensors_name=[], framework_op_debug_info="double_conv_43/Sequential_1/BatchNorm2d_10/aten_batch_norm/transpose_1", axes=[0, 3, 1, 2]) // ty=Tensor[(1, 64, 600, 600), float32]
  %265 = nn.relu(%264, framework_op_name="double_conv_43/Sequential_1/BatchNorm2d_10/aten_relu/Relu", output_tensors_name=["double_conv_43/Sequential_1/BatchNorm2d_10/aten_relu/Relu:0"], input_tensors_name=[], framework_op_debug_info="double_conv_43/Sequential_1/BatchNorm2d_10/aten_relu/Relu", axis=0) // ty=Tensor[(1, 64, 600, 600), float32]
  %266 = transpose(%265, framework_op_name="aten_upsample_bilinear2d_2/transpose", output_tensors_name=["aten_upsample_bilinear2d_2/transpose:0"], input_tensors_name=[], framework_op_debug_info="aten_upsample_bilinear2d_2/transpose", axes=[0, 2, 3, 1]) // ty=Tensor[(1, 600, 600, 64), float32]
  %267 = transpose(%266, framework_op_name="transpose4", output_tensors_name=["transpose4:0"], input_tensors_name=[], framework_op_debug_info="aten_upsample_bilinear2d_2/conv2d_transpose", axes=[0, 3, 1, 2]) // ty=Tensor[(1, 64, 600, 600), float32]
  %268 = nn.conv2d_transpose(%267, meta[relay.Constant][116] // ty=Tensor[(64, 64, 4, 4), float32], framework_op_name="nn.conv2d_transpose2", output_tensors_name=["nn.conv2d_transpose2:0"], input_tensors_name=[], framework_op_debug_info="aten_upsample_bilinear2d_2/conv2d_transpose", channels=64, kernel_size=[4, 4], strides=[2, 2], padding=[1, 1, 1, 1]) // ty=Tensor[(1, 64, 1200, 1200), float32]
  %269 = transpose(%268, framework_op_name="aten_upsample_bilinear2d_2/conv2d_transpose", output_tensors_name=["aten_upsample_bilinear2d_2/conv2d_transpose:0"], input_tensors_name=[], framework_op_debug_info="aten_upsample_bilinear2d_2/conv2d_transpose", axes=[0, 2, 3, 1]) // ty=Tensor[(1, 1200, 1200, 64), float32]
  %270 = transpose(%269, framework_op_name="aten_upsample_bilinear2d_2/transpose_1", output_tensors_name=["aten_upsample_bilinear2d_2/transpose_1:0"], input_tensors_name=[], framework_op_debug_info="aten_upsample_bilinear2d_2/transpose_1", axes=[0, 3, 1, 2]) // ty=Tensor[(1, 64, 1200, 1200), float32]
  %271 = multiply(%270, meta[relay.Constant][117] // ty=Tensor[(1200, 1200), float32], framework_op_name="aten_upsample_bilinear2d_2/Mul", output_tensors_name=["aten_upsample_bilinear2d_2/Mul:0"], input_tensors_name=[], framework_op_debug_info="aten_upsample_bilinear2d_2/Mul", axis=0) // ty=Tensor[(1, 64, 1200, 1200), float32]
  %272 = copy(%271, framework_op_name="copy7", output_tensors_name=["copy7:0"], input_tensors_name=[], framework_op_debug_info="aten_cat_3/concat", axis=0) // ty=Tensor[(1, 64, 1200, 1200), float32]
  %273 = copy(%55, framework_op_name="copy8", output_tensors_name=["copy8:0"], input_tensors_name=[], framework_op_debug_info="aten_cat_3/concat", axis=0) // ty=Tensor[(1, 128, 1200, 1200), float32]
  %274 = (%272, %273)
  %275 = concatenate(%274, framework_op_name="aten_cat_3/concat", output_tensors_name=["aten_cat_3/concat:0"], input_tensors_name=[], framework_op_debug_info="aten_cat_3/concat", axis=1) // ty=Tensor[(1, 192, 1200, 1200), float32]
  %276 = transpose(%275, framework_op_name="double_conv_59/Sequential_1/Conv2d_6/aten__convolution/transpose", output_tensors_name=["double_conv_59/Sequential_1/Conv2d_6/aten__convolution/transpose:0"], input_tensors_name=[], framework_op_debug_info="double_conv_59/Sequential_1/Conv2d_6/aten__convolution/transpose", axes=[0, 2, 3, 1]) // ty=Tensor[(1, 1200, 1200, 192), float32]
  %277 = nn.conv2d(%276, meta[relay.Constant][118] // ty=Tensor[(1, 1, 192, 64), float32], framework_op_name="double_conv_59/Sequential_1/Conv2d_6/aten__convolution/Conv2D", output_tensors_name=["double_conv_59/Sequential_1/Conv2d_6/aten__convolution/Conv2D:0"], input_tensors_name=[], framework_op_debug_info="double_conv_59/Sequential_1/Conv2d_6/aten__convolution/Conv2D", channels=64, kernel_size=[1, 1], data_layout="NHWC", kernel_layout="HWIO") // ty=Tensor[(1, 1200, 1200, 64), float32]
  %278 = add(%277, meta[relay.Constant][119] // ty=Tensor[(64,), float32], framework_op_name="double_conv_59/Sequential_1/Conv2d_6/aten__convolution/BiasAdd", output_tensors_name=["double_conv_59/Sequential_1/Conv2d_6/aten__convolution/BiasAdd:0"], input_tensors_name=[], framework_op_debug_info="double_conv_59/Sequential_1/Conv2d_6/aten__convolution/BiasAdd", axis=0) // ty=Tensor[(1, 1200, 1200, 64), float32]
  %279 = transpose(%278, framework_op_name="double_conv_59/Sequential_1/Conv2d_6/aten__convolution/transpose_2", output_tensors_name=["double_conv_59/Sequential_1/Conv2d_6/aten__convolution/transpose_2:0"], input_tensors_name=[], framework_op_debug_info="double_conv_59/Sequential_1/Conv2d_6/aten__convolution/transpose_2", axes=[0, 3, 1, 2]) // ty=Tensor[(1, 64, 1200, 1200), float32]
  %280 = transpose(%279, framework_op_name="double_conv_59/Sequential_1/BatchNorm2d_7/aten_batch_norm/transpose", output_tensors_name=["double_conv_59/Sequential_1/BatchNorm2d_7/aten_batch_norm/transpose:0"], input_tensors_name=[], framework_op_debug_info="double_conv_59/Sequential_1/BatchNorm2d_7/aten_batch_norm/transpose", axes=[0, 2, 3, 1]) // ty=Tensor[(1, 1200, 1200, 64), float32]
  %281 = subtract(%280, meta[relay.Constant][120] // ty=Tensor[(64,), float32], framework_op_name="double_conv_59/Sequential_1/BatchNorm2d_7/aten_batch_norm/sub", output_tensors_name=["double_conv_59/Sequential_1/BatchNorm2d_7/aten_batch_norm/sub:0"], input_tensors_name=[], framework_op_debug_info="double_conv_59/Sequential_1/BatchNorm2d_7/aten_batch_norm/sub", axis=0) // ty=Tensor[(1, 1200, 1200, 64), float32]
  %282 = multiply(%281, meta[relay.Constant][121] // ty=Tensor[(64,), float32], framework_op_name="double_conv_59/Sequential_1/BatchNorm2d_7/aten_batch_norm/truediv", output_tensors_name=["double_conv_59/Sequential_1/BatchNorm2d_7/aten_batch_norm/truediv:0"], input_tensors_name=[], framework_op_debug_info="double_conv_59/Sequential_1/BatchNorm2d_7/aten_batch_norm/truediv", axis=0) // ty=Tensor[(1, 1200, 1200, 64), float32]
  %283 = multiply(%282, meta[relay.Constant][122] // ty=Tensor[(64,), float32], framework_op_name="double_conv_59/Sequential_1/BatchNorm2d_7/aten_batch_norm/mul", output_tensors_name=["double_conv_59/Sequential_1/BatchNorm2d_7/aten_batch_norm/mul:0"], input_tensors_name=[], framework_op_debug_info="double_conv_59/Sequential_1/BatchNorm2d_7/aten_batch_norm/mul", axis=0) // ty=Tensor[(1, 1200, 1200, 64), float32]
  %284 = add(%283, meta[relay.Constant][123] // ty=Tensor[(64,), float32], framework_op_name="double_conv_59/Sequential_1/BatchNorm2d_7/aten_batch_norm/add_1", output_tensors_name=["double_conv_59/Sequential_1/BatchNorm2d_7/aten_batch_norm/add_1:0"], input_tensors_name=[], framework_op_debug_info="double_conv_59/Sequential_1/BatchNorm2d_7/aten_batch_norm/add_1", axis=0) // ty=Tensor[(1, 1200, 1200, 64), float32]
  %285 = transpose(%284, framework_op_name="double_conv_59/Sequential_1/BatchNorm2d_7/aten_batch_norm/transpose_1", output_tensors_name=["double_conv_59/Sequential_1/BatchNorm2d_7/aten_batch_norm/transpose_1:0"], input_tensors_name=[], framework_op_debug_info="double_conv_59/Sequential_1/BatchNorm2d_7/aten_batch_norm/transpose_1", axes=[0, 3, 1, 2]) // ty=Tensor[(1, 64, 1200, 1200), float32]
  %286 = nn.relu(%285, framework_op_name="double_conv_59/Sequential_1/BatchNorm2d_7/aten_relu/Relu", output_tensors_name=["double_conv_59/Sequential_1/BatchNorm2d_7/aten_relu/Relu:0"], input_tensors_name=[], framework_op_debug_info="double_conv_59/Sequential_1/BatchNorm2d_7/aten_relu/Relu", axis=0) // ty=Tensor[(1, 64, 1200, 1200), float32]
  %287 = transpose(%286, framework_op_name="double_conv_59/Sequential_1/Conv2d_9/aten__convolution/transpose", output_tensors_name=["double_conv_59/Sequential_1/Conv2d_9/aten__convolution/transpose:0"], input_tensors_name=[], framework_op_debug_info="double_conv_59/Sequential_1/Conv2d_9/aten__convolution/transpose", axes=[0, 2, 3, 1]) // ty=Tensor[(1, 1200, 1200, 64), float32]
  %288 = nn.pad(%287, framework_op_name="double_conv_59/Sequential_1/Conv2d_9/aten__convolution/Pad", output_tensors_name=["double_conv_59/Sequential_1/Conv2d_9/aten__convolution/Pad:0"], input_tensors_name=[], framework_op_debug_info="double_conv_59/Sequential_1/Conv2d_9/aten__convolution/Pad", pad_width=[[0, 0], [1, 1], [1, 1], [0, 0]]) // ty=Tensor[(1, 1202, 1202, 64), float32]
  %289 = nn.conv2d(%288, meta[relay.Constant][124] // ty=Tensor[(3, 3, 64, 32), float32], framework_op_name="double_conv_59/Sequential_1/Conv2d_9/aten__convolution/Conv2D", output_tensors_name=["double_conv_59/Sequential_1/Conv2d_9/aten__convolution/Conv2D:0"], input_tensors_name=[], framework_op_debug_info="double_conv_59/Sequential_1/Conv2d_9/aten__convolution/Conv2D", channels=32, kernel_size=[3, 3], data_layout="NHWC", kernel_layout="HWIO") // ty=Tensor[(1, 1200, 1200, 32), float32]
  %290 = add(%289, meta[relay.Constant][125] // ty=Tensor[(32,), float32], framework_op_name="double_conv_59/Sequential_1/Conv2d_9/aten__convolution/BiasAdd", output_tensors_name=["double_conv_59/Sequential_1/Conv2d_9/aten__convolution/BiasAdd:0"], input_tensors_name=[], framework_op_debug_info="double_conv_59/Sequential_1/Conv2d_9/aten__convolution/BiasAdd", axis=0) // ty=Tensor[(1, 1200, 1200, 32), float32]
  %291 = transpose(%290, framework_op_name="double_conv_59/Sequential_1/Conv2d_9/aten__convolution/transpose_2", output_tensors_name=["double_conv_59/Sequential_1/Conv2d_9/aten__convolution/transpose_2:0"], input_tensors_name=[], framework_op_debug_info="double_conv_59/Sequential_1/Conv2d_9/aten__convolution/transpose_2", axes=[0, 3, 1, 2]) // ty=Tensor[(1, 32, 1200, 1200), float32]
  %292 = transpose(%291, framework_op_name="double_conv_59/Sequential_1/BatchNorm2d_10/aten_batch_norm/transpose", output_tensors_name=["double_conv_59/Sequential_1/BatchNorm2d_10/aten_batch_norm/transpose:0"], input_tensors_name=[], framework_op_debug_info="double_conv_59/Sequential_1/BatchNorm2d_10/aten_batch_norm/transpose", axes=[0, 2, 3, 1]) // ty=Tensor[(1, 1200, 1200, 32), float32]
  %293 = subtract(%292, meta[relay.Constant][126] // ty=Tensor[(32,), float32], framework_op_name="double_conv_59/Sequential_1/BatchNorm2d_10/aten_batch_norm/sub", output_tensors_name=["double_conv_59/Sequential_1/BatchNorm2d_10/aten_batch_norm/sub:0"], input_tensors_name=[], framework_op_debug_info="double_conv_59/Sequential_1/BatchNorm2d_10/aten_batch_norm/sub", axis=0) // ty=Tensor[(1, 1200, 1200, 32), float32]
  %294 = multiply(%293, meta[relay.Constant][127] // ty=Tensor[(32,), float32], framework_op_name="double_conv_59/Sequential_1/BatchNorm2d_10/aten_batch_norm/truediv", output_tensors_name=["double_conv_59/Sequential_1/BatchNorm2d_10/aten_batch_norm/truediv:0"], input_tensors_name=[], framework_op_debug_info="double_conv_59/Sequential_1/BatchNorm2d_10/aten_batch_norm/truediv", axis=0) // ty=Tensor[(1, 1200, 1200, 32), float32]
  %295 = multiply(%294, meta[relay.Constant][128] // ty=Tensor[(32,), float32], framework_op_name="double_conv_59/Sequential_1/BatchNorm2d_10/aten_batch_norm/mul", output_tensors_name=["double_conv_59/Sequential_1/BatchNorm2d_10/aten_batch_norm/mul:0"], input_tensors_name=[], framework_op_debug_info="double_conv_59/Sequential_1/BatchNorm2d_10/aten_batch_norm/mul", axis=0) // ty=Tensor[(1, 1200, 1200, 32), float32]
  %296 = add(%295, meta[relay.Constant][129] // ty=Tensor[(32,), float32], framework_op_name="double_conv_59/Sequential_1/BatchNorm2d_10/aten_batch_norm/add_1", output_tensors_name=["double_conv_59/Sequential_1/BatchNorm2d_10/aten_batch_norm/add_1:0"], input_tensors_name=[], framework_op_debug_info="double_conv_59/Sequential_1/BatchNorm2d_10/aten_batch_norm/add_1", axis=0) // ty=Tensor[(1, 1200, 1200, 32), float32]
  %297 = transpose(%296, framework_op_name="double_conv_59/Sequential_1/BatchNorm2d_10/aten_batch_norm/transpose_1", output_tensors_name=["double_conv_59/Sequential_1/BatchNorm2d_10/aten_batch_norm/transpose_1:0"], input_tensors_name=[], framework_op_debug_info="double_conv_59/Sequential_1/BatchNorm2d_10/aten_batch_norm/transpose_1", axes=[0, 3, 1, 2]) // ty=Tensor[(1, 32, 1200, 1200), float32]
  %298 = nn.relu(%297, framework_op_name="nn.relu0", output_tensors_name=["nn.relu0:0"], input_tensors_name=[], framework_op_debug_info="", axis=0) // ty=Tensor[(1, 32, 1200, 1200), float32]
  %299 = transpose(%298, framework_op_name="Sequential_60/Conv2d_9/aten__convolution/transpose", output_tensors_name=["Sequential_60/Conv2d_9/aten__convolution/transpose:0"], input_tensors_name=[], framework_op_debug_info="Sequential_60/Conv2d_9/aten__convolution/transpose", axes=[0, 2, 3, 1]) // ty=Tensor[(1, 1200, 1200, 32), float32]
  %300 = nn.pad(%299, framework_op_name="Sequential_60/Conv2d_9/aten__convolution/Pad", output_tensors_name=["Sequential_60/Conv2d_9/aten__convolution/Pad:0"], input_tensors_name=[], framework_op_debug_info="Sequential_60/Conv2d_9/aten__convolution/Pad", pad_width=[[0, 0], [1, 1], [1, 1], [0, 0]]) // ty=Tensor[(1, 1202, 1202, 32), float32]
  %301 = nn.conv2d(%300, meta[relay.Constant][130] // ty=Tensor[(3, 3, 32, 32), float32], framework_op_name="Sequential_60/Conv2d_9/aten__convolution/Conv2D", output_tensors_name=["Sequential_60/Conv2d_9/aten__convolution/Conv2D:0"], input_tensors_name=[], framework_op_debug_info="Sequential_60/Conv2d_9/aten__convolution/Conv2D", channels=32, kernel_size=[3, 3], data_layout="NHWC", kernel_layout="HWIO") // ty=Tensor[(1, 1200, 1200, 32), float32]
  %302 = add(%301, meta[relay.Constant][131] // ty=Tensor[(32,), float32], framework_op_name="Sequential_60/Conv2d_9/aten__convolution/BiasAdd", output_tensors_name=["Sequential_60/Conv2d_9/aten__convolution/BiasAdd:0"], input_tensors_name=[], framework_op_debug_info="Sequential_60/Conv2d_9/aten__convolution/BiasAdd", axis=0) // ty=Tensor[(1, 1200, 1200, 32), float32]
  %303 = transpose(%302, framework_op_name="Sequential_60/Conv2d_9/aten__convolution/transpose_2", output_tensors_name=["Sequential_60/Conv2d_9/aten__convolution/transpose_2:0"], input_tensors_name=[], framework_op_debug_info="Sequential_60/Conv2d_9/aten__convolution/transpose_2", axes=[0, 3, 1, 2]) // ty=Tensor[(1, 32, 1200, 1200), float32]
  %304 = nn.relu(%303, framework_op_name="Sequential_60/Conv2d_9/aten_relu/Relu", output_tensors_name=["Sequential_60/Conv2d_9/aten_relu/Relu:0"], input_tensors_name=[], framework_op_debug_info="Sequential_60/Conv2d_9/aten_relu/Relu", axis=0) // ty=Tensor[(1, 32, 1200, 1200), float32]
  %305 = transpose(%304, framework_op_name="Sequential_60/Conv2d_11/aten__convolution/transpose", output_tensors_name=["Sequential_60/Conv2d_11/aten__convolution/transpose:0"], input_tensors_name=[], framework_op_debug_info="Sequential_60/Conv2d_11/aten__convolution/transpose", axes=[0, 2, 3, 1]) // ty=Tensor[(1, 1200, 1200, 32), float32]
  %306 = nn.pad(%305, framework_op_name="Sequential_60/Conv2d_11/aten__convolution/Pad", output_tensors_name=["Sequential_60/Conv2d_11/aten__convolution/Pad:0"], input_tensors_name=[], framework_op_debug_info="Sequential_60/Conv2d_11/aten__convolution/Pad", pad_width=[[0, 0], [1, 1], [1, 1], [0, 0]]) // ty=Tensor[(1, 1202, 1202, 32), float32]
  %307 = nn.conv2d(%306, meta[relay.Constant][132] // ty=Tensor[(3, 3, 32, 32), float32], framework_op_name="Sequential_60/Conv2d_11/aten__convolution/Conv2D", output_tensors_name=["Sequential_60/Conv2d_11/aten__convolution/Conv2D:0"], input_tensors_name=[], framework_op_debug_info="Sequential_60/Conv2d_11/aten__convolution/Conv2D", channels=32, kernel_size=[3, 3], data_layout="NHWC", kernel_layout="HWIO") // ty=Tensor[(1, 1200, 1200, 32), float32]
  %308 = add(%307, meta[relay.Constant][133] // ty=Tensor[(32,), float32], framework_op_name="Sequential_60/Conv2d_11/aten__convolution/BiasAdd", output_tensors_name=["Sequential_60/Conv2d_11/aten__convolution/BiasAdd:0"], input_tensors_name=[], framework_op_debug_info="Sequential_60/Conv2d_11/aten__convolution/BiasAdd", axis=0) // ty=Tensor[(1, 1200, 1200, 32), float32]
  %309 = transpose(%308, framework_op_name="Sequential_60/Conv2d_11/aten__convolution/transpose_2", output_tensors_name=["Sequential_60/Conv2d_11/aten__convolution/transpose_2:0"], input_tensors_name=[], framework_op_debug_info="Sequential_60/Conv2d_11/aten__convolution/transpose_2", axes=[0, 3, 1, 2]) // ty=Tensor[(1, 32, 1200, 1200), float32]
  %310 = nn.relu(%309, framework_op_name="Sequential_60/Conv2d_11/aten_relu/Relu", output_tensors_name=["Sequential_60/Conv2d_11/aten_relu/Relu:0"], input_tensors_name=[], framework_op_debug_info="Sequential_60/Conv2d_11/aten_relu/Relu", axis=0) // ty=Tensor[(1, 32, 1200, 1200), float32]
  %311 = transpose(%310, framework_op_name="Sequential_60/Conv2d_13/aten__convolution/transpose", output_tensors_name=["Sequential_60/Conv2d_13/aten__convolution/transpose:0"], input_tensors_name=[], framework_op_debug_info="Sequential_60/Conv2d_13/aten__convolution/transpose", axes=[0, 2, 3, 1]) // ty=Tensor[(1, 1200, 1200, 32), float32]
  %312 = nn.pad(%311, framework_op_name="Sequential_60/Conv2d_13/aten__convolution/Pad", output_tensors_name=["Sequential_60/Conv2d_13/aten__convolution/Pad:0"], input_tensors_name=[], framework_op_debug_info="Sequential_60/Conv2d_13/aten__convolution/Pad", pad_width=[[0, 0], [1, 1], [1, 1], [0, 0]]) // ty=Tensor[(1, 1202, 1202, 32), float32]
  %313 = nn.conv2d(%312, meta[relay.Constant][134] // ty=Tensor[(3, 3, 32, 16), float32], framework_op_name="Sequential_60/Conv2d_13/aten__convolution/Conv2D", output_tensors_name=["Sequential_60/Conv2d_13/aten__convolution/Conv2D:0"], input_tensors_name=[], framework_op_debug_info="Sequential_60/Conv2d_13/aten__convolution/Conv2D", channels=16, kernel_size=[3, 3], data_layout="NHWC", kernel_layout="HWIO") // ty=Tensor[(1, 1200, 1200, 16), float32]
  %314 = add(%313, meta[relay.Constant][135] // ty=Tensor[(16,), float32], framework_op_name="Sequential_60/Conv2d_13/aten__convolution/BiasAdd", output_tensors_name=["Sequential_60/Conv2d_13/aten__convolution/BiasAdd:0"], input_tensors_name=[], framework_op_debug_info="Sequential_60/Conv2d_13/aten__convolution/BiasAdd", axis=0) // ty=Tensor[(1, 1200, 1200, 16), float32]
  %315 = transpose(%314, framework_op_name="Sequential_60/Conv2d_13/aten__convolution/transpose_2", output_tensors_name=["Sequential_60/Conv2d_13/aten__convolution/transpose_2:0"], input_tensors_name=[], framework_op_debug_info="Sequential_60/Conv2d_13/aten__convolution/transpose_2", axes=[0, 3, 1, 2]) // ty=Tensor[(1, 16, 1200, 1200), float32]
  %316 = nn.relu(%315, framework_op_name="Sequential_60/Conv2d_13/aten_relu/Relu", output_tensors_name=["Sequential_60/Conv2d_13/aten_relu/Relu:0"], input_tensors_name=[], framework_op_debug_info="Sequential_60/Conv2d_13/aten_relu/Relu", axis=0) // ty=Tensor[(1, 16, 1200, 1200), float32]
  %317 = transpose(%316, framework_op_name="Sequential_60/Conv2d_15/aten__convolution/transpose", output_tensors_name=["Sequential_60/Conv2d_15/aten__convolution/transpose:0"], input_tensors_name=[], framework_op_debug_info="Sequential_60/Conv2d_15/aten__convolution/transpose", axes=[0, 2, 3, 1]) // ty=Tensor[(1, 1200, 1200, 16), float32]
  %318 = nn.conv2d(%317, meta[relay.Constant][136] // ty=Tensor[(1, 1, 16, 16), float32], framework_op_name="Sequential_60/Conv2d_15/aten__convolution/Conv2D", output_tensors_name=["Sequential_60/Conv2d_15/aten__convolution/Conv2D:0"], input_tensors_name=[], framework_op_debug_info="Sequential_60/Conv2d_15/aten__convolution/Conv2D", channels=16, kernel_size=[1, 1], data_layout="NHWC", kernel_layout="HWIO") // ty=Tensor[(1, 1200, 1200, 16), float32]
  %319 = add(%318, meta[relay.Constant][137] // ty=Tensor[(16,), float32], framework_op_name="Sequential_60/Conv2d_15/aten__convolution/BiasAdd", output_tensors_name=["Sequential_60/Conv2d_15/aten__convolution/BiasAdd:0"], input_tensors_name=[], framework_op_debug_info="Sequential_60/Conv2d_15/aten__convolution/BiasAdd", axis=0) // ty=Tensor[(1, 1200, 1200, 16), float32]
  %320 = transpose(%319, framework_op_name="Sequential_60/Conv2d_15/aten__convolution/transpose_2", output_tensors_name=["Sequential_60/Conv2d_15/aten__convolution/transpose_2:0"], input_tensors_name=[], framework_op_debug_info="Sequential_60/Conv2d_15/aten__convolution/transpose_2", axes=[0, 3, 1, 2]) // ty=Tensor[(1, 16, 1200, 1200), float32]
  %321 = nn.relu(%320, framework_op_name="Sequential_60/Conv2d_15/aten_relu/Relu", output_tensors_name=["Sequential_60/Conv2d_15/aten_relu/Relu:0"], input_tensors_name=[], framework_op_debug_info="Sequential_60/Conv2d_15/aten_relu/Relu", axis=0) // ty=Tensor[(1, 16, 1200, 1200), float32]
  %322 = transpose(%321, framework_op_name="Sequential_60/Conv2d_17/aten__convolution/transpose", output_tensors_name=["Sequential_60/Conv2d_17/aten__convolution/transpose:0"], input_tensors_name=[], framework_op_debug_info="Sequential_60/Conv2d_17/aten__convolution/transpose", axes=[0, 2, 3, 1]) // ty=Tensor[(1, 1200, 1200, 16), float32]
  %323 = nn.conv2d(%322, meta[relay.Constant][138] // ty=Tensor[(1, 1, 16, 2), float32], framework_op_name="Sequential_60/Conv2d_17/aten__convolution/Conv2D", output_tensors_name=["Sequential_60/Conv2d_17/aten__convolution/Conv2D:0"], input_tensors_name=[], framework_op_debug_info="Sequential_60/Conv2d_17/aten__convolution/Conv2D", channels=2, kernel_size=[1, 1], data_layout="NHWC", kernel_layout="HWIO") // ty=Tensor[(1, 1200, 1200, 2), float32]
  %324 = add(%323, meta[relay.Constant][139] // ty=Tensor[(2,), float32], framework_op_name="Sequential_60/Conv2d_17/aten__convolution/BiasAdd", output_tensors_name=["Sequential_60/Conv2d_17/aten__convolution/BiasAdd:0"], input_tensors_name=[], framework_op_debug_info="Sequential_60/Conv2d_17/aten__convolution/BiasAdd", axis=0) // ty=Tensor[(1, 1200, 1200, 2), float32]
  %325 = transpose(%324, framework_op_name="Sequential_60/Conv2d_17/aten__convolution/transpose_2", output_tensors_name=["Sequential_60/Conv2d_17/aten__convolution/transpose_2:0"], input_tensors_name=[], framework_op_debug_info="Sequential_60/Conv2d_17/aten__convolution/transpose_2", axes=[0, 3, 1, 2]) // ty=Tensor[(1, 2, 1200, 1200), float32]
  %326 = transpose(%325, framework_op_name="transpose7", output_tensors_name=["transpose7:0"], input_tensors_name=[], framework_op_debug_info="", axes=[0, 2, 3, 1]) // ty=Tensor[(1, 1200, 1200, 2), float32]
  %327 = copy(%326, framework_op_name="aten_permute/transpose", output_tensors_name=["aten_permute/transpose:0"], input_tensors_name=[], framework_op_debug_info="aten_permute/transpose", axis=0) // ty=Tensor[(1, 1200, 1200, 2), float32]
  %328 = copy(%298, framework_op_name="double_conv_59/Sequential_1/BatchNorm2d_10/aten_relu/Relu", output_tensors_name=["double_conv_59/Sequential_1/BatchNorm2d_10/aten_relu/Relu:0"], input_tensors_name=[], framework_op_debug_info="double_conv_59/Sequential_1/BatchNorm2d_10/aten_relu/Relu", axis=0) // ty=Tensor[(1, 32, 1200, 1200), float32]
  %329 = (%327, %328)
  %329
}
%330
// meta data omitted. you can use show_meta_data=True to include meta data